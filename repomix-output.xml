This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
app/
  api/
    chat/
      route.ts
    podcast-metadata/
      route.ts
    summarize/
      route.ts
  auth/
    auth-code-error/
      page.tsx
    callback/
      route.ts
  dashboard/
    page.tsx
  validate-metadata/
    page.tsx
  validate-transcript/
    page.tsx
  globals.css
  layout.tsx
  page.tsx
  page.tsx.backup
components/
  Chat.tsx
  ErrorBoundary.tsx
  Navbar.tsx
  PodcastHeader.tsx
  PodcastMetadata.tsx
  Summary.tsx
lib/
  supabase/
    client.ts
    server.ts
  supabaseClient.ts
public/
  create-screenshot.html
  README.md
.gitignore
DEPLOYMENT_VERCEL.md
middleware.ts
package.json
postcss.config.js
README.md
supabaseplan.md
tailwind.config.js
TRANSCRIPT_ISSUE_PLAN.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="app/api/podcast-metadata/route.ts">
import { NextRequest, NextResponse } from "next/server";

// Helper function to truncate description
const truncateDescription = (
  description: string,
  maxLength: number = 300
): string => {
  if (!description) return "";
  if (description.length <= maxLength) return description;
  return description.substring(0, maxLength) + "...";
};

// Actual function to fetch YouTube metadata using the YouTube Data API
const fetchYouTubeMetadata = async (
  videoId: string,
  includeFull: boolean = false
) => {
  try {
    // Use YouTube Data API to get detailed video information
    const apiKey = process.env.YOUTUBE_API_KEY;

    if (!apiKey) {
      throw new Error("YouTube API key is not configured");
    }

    // Fetch detailed video information from the YouTube Data API
    const videoDetailsUrl = `https://www.googleapis.com/youtube/v3/videos?id=${videoId}&part=snippet,contentDetails,statistics&key=${apiKey}`;
    const videoResponse = await fetch(videoDetailsUrl);

    if (!videoResponse.ok) {
      throw new Error(
        `Failed to fetch video details: ${videoResponse.statusText}`
      );
    }

    const videoData = await videoResponse.json();

    if (!videoData.items || videoData.items.length === 0) {
      throw new Error("No video details found");
    }

    const videoDetails = videoData.items[0];
    const snippet = videoDetails.snippet;
    const contentDetails = videoDetails.contentDetails;

    // Use the YouTube oEmbed API as a fallback for some data
    const oEmbedResponse = await fetch(
      `https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v=${videoId}&format=json`
    );
    const oEmbedData = oEmbedResponse.ok ? await oEmbedResponse.json() : null;

    // Format the ISO 8601 duration to a readable format
    const duration = contentDetails.duration
      ? formatISODuration(contentDetails.duration)
      : "Unknown duration";

    const fullDescription =
      snippet.description || oEmbedData?.title || "No description available.";

    return {
      title: snippet.title || oEmbedData?.title || "Unknown Title",
      channelName:
        snippet.channelTitle || oEmbedData?.author_name || "Unknown Channel",
      duration: duration,
      videoId: videoId,
      description: includeFull
        ? fullDescription
        : truncateDescription(fullDescription),
      fullDescription: fullDescription, // Always include the full description for reference
      descriptionTruncated: fullDescription.length > 300, // Flag indicating if description was truncated
      publishedAt: snippet.publishedAt || null,
      viewCount: videoDetails.statistics?.viewCount || null,
      likeCount: videoDetails.statistics?.likeCount || null,
      thumbnails: snippet.thumbnails || null,
    };
  } catch (error: any) {
    console.error("Error fetching YouTube metadata:", error);
    // Fallback to oEmbed if the YouTube Data API fails
    try {
      const oEmbedResponse = await fetch(
        `https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v=${videoId}&format=json`
      );

      if (oEmbedResponse.ok) {
        const oEmbedData = await oEmbedResponse.json();
        return {
          title: oEmbedData.title || "YouTube Video",
          channelName: oEmbedData.author_name || "Unknown Channel",
          duration: "Unknown duration",
          videoId: videoId,
          description: "Could not retrieve full video description.",
          fullDescription: "Could not retrieve full video description.",
          descriptionTruncated: false,
        };
      }
    } catch (fallbackError) {
      console.error("Fallback to oEmbed also failed:", fallbackError);
    }

    // Return basic info with the video ID we have if all else fails
    return {
      title: "YouTube Video",
      channelName: "Unknown Channel",
      duration: "Unknown duration",
      videoId: videoId,
      description: "Could not retrieve video information.",
      fullDescription: "Could not retrieve video information.",
      descriptionTruncated: false,
    };
  }
};

// Helper function to format ISO 8601 duration to readable time
const formatISODuration = (isoDuration: string): string => {
  // ISO 8601 duration format: PT#H#M#S
  const regex = /PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?/;
  const matches = isoDuration.match(regex);

  if (!matches) {
    return "Unknown duration";
  }

  const hours = matches[1] ? parseInt(matches[1]) : 0;
  const minutes = matches[2] ? parseInt(matches[2]) : 0;
  const seconds = matches[3] ? parseInt(matches[3]) : 0;

  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, "0")}:${seconds
      .toString()
      .padStart(2, "0")}`;
  }

  return `${minutes}:${seconds.toString().padStart(2, "0")}`;
};

export async function POST(request: NextRequest) {
  try {
    const { url, includeFull } = await request.json();

    // Extract video ID from URL
    const videoIdMatch = url.match(
      /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
    );

    if (!videoIdMatch) {
      return NextResponse.json(
        { error: "Could not extract video ID from URL" },
        { status: 400 }
      );
    }

    const videoId = videoIdMatch[1];

    // Fetch metadata from YouTube
    const metadata = await fetchYouTubeMetadata(videoId, includeFull);

    return NextResponse.json({ metadata });
  } catch (error) {
    console.error("Error processing podcast metadata:", error);
    return NextResponse.json(
      { error: "Failed to fetch podcast metadata" },
      { status: 500 }
    );
  }
}
</file>

<file path="app/auth/auth-code-error/page.tsx">
import React from "react";

export default function AuthCodeError() {
  return (
    <div
      style={{ padding: "20px", fontFamily: "sans-serif", textAlign: "center" }}
    >
      <h1>Authentication Error</h1>
      <p>
        Sorry, we couldn't sign you in. There was an issue during the
        authentication process.
      </p>
      <p>Please try signing in again.</p>
      <a href="/">Go back to Home</a>
    </div>
  );
}
</file>

<file path="app/auth/callback/route.ts">
import { createServerClient, type CookieOptions } from "@supabase/ssr";
import { cookies } from "next/headers";
import { NextResponse, type NextRequest } from "next/server";

export async function GET(request: NextRequest) {
  const { searchParams, origin } = new URL(request.url);
  const code = searchParams.get("code");
  // if "next" is in param, use it as the redirect URL
  const next = searchParams.get("next") ?? "/dashboard"; // Default redirect to dashboard

  if (code) {
    const cookieStore = cookies();
    const supabase = createServerClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      {
        cookies: {
          get(name: string) {
            return cookieStore.get(name)?.value;
          },
          set(name: string, value: string, options: CookieOptions) {
            cookieStore.set({ name, value, ...options });
          },
          remove(name: string, options: CookieOptions) {
            cookieStore.delete({ name, ...options });
          },
        },
      }
    );
    const { error } = await supabase.auth.exchangeCodeForSession(code);
    if (!error) {
      return NextResponse.redirect(`${origin}${next}`);
    }
  }

  // return the user to an error page with instructions
  console.error("Error exchanging code for session or code not found");
  return NextResponse.redirect(`${origin}/auth/auth-code-error`);
}
</file>

<file path="app/dashboard/page.tsx">
"use client";

import React, { useState, useEffect } from "react";
import { ArrowPathIcon } from "@heroicons/react/24/solid";
import toast, { Toaster } from "react-hot-toast";
import Summary from "../../components/Summary";
import Chat from "../../components/Chat";
import Navbar from "../../components/Navbar";
import PodcastHeader from "../../components/PodcastHeader";
import { PodcastMetadataProvider } from "../../components/PodcastMetadata";

export default function Dashboard() {
  const [url, setUrl] = useState("");
  const [loading, setLoading] = useState(false);
  const [validating, setValidating] = useState(false);
  const [summary, setSummary] = useState<string | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [activeTab, setActiveTab] = useState<"summary" | "chat">("summary");
  const [isUrlValidated, setIsUrlValidated] = useState(false);
  const [isSummaryLoading, setIsSummaryLoading] = useState(false);
  const [isChatLoading, setIsChatLoading] = useState(false);

  // Function to validate YouTube URL format
  const isValidYoutubeUrl = (url: string): boolean => {
    const youtubeRegex = /^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.be)\/.+/;
    return youtubeRegex.test(url);
  };

  // Extract video ID from URL
  const extractVideoId = (url: string): string | null => {
    const match = url.match(
      /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
    );
    return match ? match[1] : null;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError(null);

    if (!isValidYoutubeUrl(url)) {
      toast.error("Please enter a valid YouTube URL");
      return;
    }

    const videoId = extractVideoId(url);
    if (!videoId) {
      toast.error("Could not extract video ID from URL");
      return;
    }

    setLoading(true);
    setIsSummaryLoading(true);
    setSummary(null);

    try {
      console.log("Submitting URL:", url);
      const response = await fetch("/api/summarize", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ url }),
      });

      const data = await response.json();
      console.log("Response:", data);

      if (!response.ok) {
        throw new Error(data.error || "Failed to generate summary");
      }

      setSummary(data.summary);
      setIsUrlValidated(true);
      toast.success("Summary generated successfully!");
    } catch (error) {
      console.error("Error:", error);
      const errorMessage =
        error instanceof Error ? error.message : "Failed to generate summary";
      setError(errorMessage);
      toast.error(errorMessage);
    } finally {
      setLoading(false);
      setIsSummaryLoading(false);
    }
  };

  const validateUrl = async () => {
    if (!isValidYoutubeUrl(url)) {
      toast.error("Please enter a valid YouTube URL");
      return;
    }

    const videoId = extractVideoId(url);
    if (!videoId) {
      toast.error("Could not extract video ID from URL");
      return;
    }

    setValidating(true);
    setIsChatLoading(true);
    setError(null);

    try {
      // Just check if the transcript exists
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url,
          question:
            "Just checking if the transcript exists. Please respond with 'Yes'.",
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || "Failed to validate URL");
      }

      setIsUrlValidated(true);
      setActiveTab("chat");
      toast.success("Podcast loaded successfully!");
    } catch (error) {
      console.error("Error:", error);
      const errorMessage =
        error instanceof Error ? error.message : "Failed to validate URL";
      setError(errorMessage);
      toast.error(errorMessage);
    } finally {
      setValidating(false);
      setIsChatLoading(false);
    }
  };

  const handleTabChange = (tab: "summary" | "chat") => {
    if (loading || validating) return;

    setActiveTab(tab);

    // If switching to chat and URL is not yet validated, validate it
    if (tab === "chat" && !isUrlValidated && url) {
      validateUrl();
    }

    // If switching to summary and no summary exists yet, generate it
    if (tab === "summary" && !summary && isUrlValidated) {
      setIsSummaryLoading(true);
      handleSubmit(new Event("submit") as any);
    }
  };

  // Handle URL input change
  const handleUrlChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setUrl(e.target.value);
    // Reset validation state when URL changes
    if (isUrlValidated) {
      setIsUrlValidated(false);
      setSummary(null);
    }
  };

  return (
    <div className="min-h-screen bg-[#f7f7ff]">
      <Navbar />
      <Toaster position="bottom-right" />

      <div className="max-w-7xl mx-auto px-4">
        <div className="pt-8 pb-16 md:pt-12 md:pb-24 text-center">
          <h1 className="text-5xl md:text-6xl font-bold text-purple-700 mb-6">
            Transform Podcasts into
            <br />
            Interactive Conversations
          </h1>
          <p className="text-lg text-gray-600 max-w-3xl mx-auto mb-10">
            Paste any podcast URL and let AI create summaries and engage in
            meaningful conversations about the content
          </p>

          <div className="max-w-3xl mx-auto bg-white p-8 rounded-2xl shadow-md">
            <div className="flex items-center mb-4">
              <div className="w-6 h-6 mr-2">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                  className="text-purple-600"
                >
                  <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
                  <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
                </svg>
              </div>
              <h2 className="text-xl font-semibold">Enter Podcast URL</h2>
            </div>

            <form onSubmit={handleSubmit}>
              <div className="flex flex-col gap-4">
                <div className="flex flex-col md:flex-row gap-2">
                  <input
                    id="youtube-url"
                    type="text"
                    value={url}
                    onChange={handleUrlChange}
                    placeholder="https://podcast-url.com/episode"
                    className="flex-1 p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-purple-500"
                    disabled={loading || validating}
                    aria-label="YouTube URL"
                  />
                  <button
                    type="submit"
                    disabled={loading || validating || !url.trim()}
                    className="px-6 py-3 bg-purple-600 text-white rounded-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center"
                    aria-label={loading ? "Processing..." : "Analyze"}
                  >
                    {loading ? (
                      <div className="flex items-center">
                        <ArrowPathIcon className="w-5 h-5 animate-spin mr-2" />
                        <span>Processing...</span>
                      </div>
                    ) : (
                      <div className="flex items-center">
                        <svg
                          xmlns="http://www.w3.org/2000/svg"
                          viewBox="0 0 24 24"
                          fill="currentColor"
                          className="w-5 h-5 mr-2"
                        >
                          <path d="M18.375 2.25c-1.035 0-1.875.84-1.875 1.875v15.75c0 1.035.84 1.875 1.875 1.875h.75c1.035 0 1.875-.84 1.875-1.875V4.125c0-1.036-.84-1.875-1.875-1.875h-.75zM9.75 8.625c0-1.036.84-1.875 1.875-1.875h.75c1.036 0 1.875.84 1.875 1.875v11.25c0 1.035-.84 1.875-1.875 1.875h-.75c-1.036 0-1.875-.84-1.875-1.875V8.625zM3 13.125c0-1.036.84-1.875 1.875-1.875h.75c1.036 0 1.875.84 1.875 1.875v6.75c0 1.035-.84 1.875-1.875 1.875h-.75C3.84 21.75 3 20.91 3 19.875v-6.75z" />
                        </svg>
                        Analyze
                      </div>
                    )}
                  </button>
                </div>
                {error && (
                  <div className="text-red-600 text-sm p-2 bg-red-50 rounded">
                    Error: {error}
                  </div>
                )}
              </div>
            </form>
          </div>
        </div>

        {/* Feature Cards Section - only shown when no podcast summary is generated */}
        {!isUrlValidated && (
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8 max-w-7xl mx-auto px-4 pb-20">
            {/* Smart Summaries Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M12 6.042A8.967 8.967 0 006 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 016 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 016-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0018 18a8.967 8.967 0 00-6 2.292m0-14.25v14.25" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Smart Summaries
              </h3>
              <p className="text-gray-600">
                Get comprehensive summaries that capture the key points and
                insights from any podcast.
              </p>
            </div>

            {/* Interactive Chat Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M4.913 2.658c2.075-.27 4.19-.408 6.337-.408 2.147 0 4.262.139 6.337.408 1.922.25 3.291 1.861 3.405 3.727a4.403 4.403 0 00-1.032-.211 50.89 50.89 0 00-8.42 0c-2.358.196-4.04 2.19-4.04 4.434v4.286a4.47 4.47 0 002.433 3.984L7.28 21.53A.75.75 0 016 21v-4.03a48.527 48.527 0 01-1.087-.128C2.905 16.58 1.5 14.833 1.5 12.862V6.638c0-1.97 1.405-3.718 3.413-3.979z" />
                  <path d="M15.75 7.5c-1.376 0-2.739.057-4.086.169C10.124 7.797 9 9.103 9 10.609v4.285c0 1.507 1.128 2.814 2.67 2.94 1.243.102 2.5.157 3.768.165l2.782 2.781a.75.75 0 001.28-.53v-2.39l.33-.026c1.542-.125 2.67-1.433 2.67-2.94v-4.286c0-1.505-1.125-2.811-2.664-2.94A49.392 49.392 0 0015.75 7.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Interactive Chat
              </h3>
              <p className="text-gray-600">
                Ask questions about the podcast content and get detailed answers
                from our AI assistant.
              </p>
            </div>

            {/* Works Everywhere Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
                  <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Works Everywhere
              </h3>
              <p className="text-gray-600">
                Compatible with podcasts from Spotify, Apple Podcasts, YouTube,
                and many more platforms.
              </p>
            </div>

            {/* AI-Powered Insights Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M21.731 2.269a2.625 2.625 0 00-3.712 0l-1.157 1.157 3.712 3.712 1.157-1.157a2.625 2.625 0 000-3.712zM19.513 8.199l-3.712-3.712-8.4 8.4a5.25 5.25 0 00-1.32 2.214l-.8 2.685a.75.75 0 00.933.933l2.685-.8a5.25 5.25 0 002.214-1.32l8.4-8.4z" />
                  <path d="M5.25 5.25a3 3 0 00-3 3v10.5a3 3 0 003 3h10.5a3 3 0 003-3V13.5a.75.75 0 00-1.5 0v5.25a1.5 1.5 0 01-1.5 1.5H5.25a1.5 1.5 0 01-1.5-1.5V8.25a1.5 1.5 0 011.5-1.5h5.25a.75.75 0 000-1.5H5.25z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                AI-Powered Insights
              </h3>
              <p className="text-gray-600">
                Advanced AI analyzes podcasts to extract the most relevant
                information and context.
              </p>
            </div>
          </div>
        )}

        {isUrlValidated && (
          <div className="max-w-5xl mx-auto">
            <PodcastMetadataProvider videoUrl={url}>
              {(metadata, metadataLoading) => (
                <>
                  {metadata && (
                    <PodcastHeader
                      videoId={metadata.videoId}
                      title={metadata.title}
                      channelName={metadata.channelName}
                      duration={metadata.duration}
                      viewCount={metadata.viewCount}
                      likeCount={metadata.likeCount}
                      publishedAt={metadata.publishedAt}
                      onChatClick={() => handleTabChange("chat")}
                      activeTab={activeTab}
                    />
                  )}

                  <div className="bg-white rounded-lg mb-8">
                    <div className="flex border-b">
                      <button
                        onClick={() => handleTabChange("summary")}
                        className={`flex-1 py-4 font-medium text-center transition-colors ${
                          activeTab === "summary"
                            ? "text-purple-600 border-b-2 border-purple-600 bg-purple-50"
                            : "text-gray-500 hover:text-gray-700 hover:bg-gray-50"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Summary tab"
                        aria-selected={activeTab === "summary"}
                        role="tab"
                      >
                        <div className="flex items-center justify-center">
                          <svg
                            xmlns="http://www.w3.org/2000/svg"
                            className="h-5 w-5 mr-2"
                            fill="none"
                            viewBox="0 0 24 24"
                            stroke="currentColor"
                          >
                            <path
                              strokeLinecap="round"
                              strokeLinejoin="round"
                              strokeWidth={2}
                              d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-14.25C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"
                            />
                          </svg>
                          <span>Summary</span>
                          {isSummaryLoading && (
                            <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                          )}
                        </div>
                      </button>
                      <button
                        onClick={() => handleTabChange("chat")}
                        className={`flex-1 py-4 font-medium text-center transition-colors ${
                          activeTab === "chat"
                            ? "text-purple-600 border-b-2 border-purple-600 bg-purple-50"
                            : "text-gray-500 hover:text-gray-700 hover:bg-gray-50"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Chat Assistant tab"
                        aria-selected={activeTab === "chat"}
                        role="tab"
                      >
                        <div className="flex items-center justify-center">
                          <svg
                            xmlns="http://www.w3.org/2000/svg"
                            className="h-5 w-5 mr-2"
                            fill="none"
                            viewBox="0 0 24 24"
                            stroke="currentColor"
                          >
                            <path
                              strokeLinecap="round"
                              strokeLinejoin="round"
                              strokeWidth={2}
                              d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"
                            />
                          </svg>
                          <span>Chat Assistant</span>
                          {isChatLoading && (
                            <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                          )}
                        </div>
                      </button>
                    </div>

                    <div
                      role="tabpanel"
                      aria-label="Tab Content"
                      className="w-full"
                    >
                      <div className="max-w-full">
                        {activeTab === "summary" && (
                          <Summary summary={summary || ""} videoUrl={url} />
                        )}
                        {activeTab === "chat" && <Chat videoUrl={url} />}
                      </div>
                    </div>
                  </div>
                </>
              )}
            </PodcastMetadataProvider>
          </div>
        )}
      </div>
    </div>
  );
}
</file>

<file path="app/validate-metadata/page.tsx">
"use client";

import { useState } from "react";

export default function ValidateMetadata() {
  const [url, setUrl] = useState("");
  const [metadata, setMetadata] = useState<any>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [showFullDescription, setShowFullDescription] = useState(false);

  const validateMetadata = async () => {
    setLoading(true);
    setError("");
    setShowFullDescription(false); // Reset description state on new validation
    try {
      const response = await fetch("/api/podcast-metadata", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url,
          includeFull: true, // Always request the full description in the API
        }),
      });

      const data = await response.json();
      if (!response.ok) {
        throw new Error(data.error || "Failed to validate metadata");
      }

      setMetadata(data.metadata);
    } catch (err: any) {
      setError(err.message || "An error occurred");
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="p-6 max-w-4xl mx-auto">
      <h1 className="text-2xl font-bold mb-4">YouTube Metadata Validator</h1>
      <div className="mb-4">
        <input
          type="text"
          value={url}
          onChange={(e) => setUrl(e.target.value)}
          placeholder="Enter YouTube URL"
          className="w-full p-2 border rounded"
        />
      </div>
      <button
        onClick={validateMetadata}
        disabled={loading}
        className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-blue-300"
      >
        {loading ? "Validating..." : "Validate Metadata"}
      </button>

      {error && (
        <div className="mt-4 p-3 bg-red-100 text-red-700 rounded">{error}</div>
      )}

      {metadata && (
        <div className="mt-6">
          <h2 className="text-xl font-semibold mb-2">Metadata Results:</h2>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
            <div className="bg-gray-50 p-4 rounded shadow">
              <h3 className="font-medium text-lg mb-2">Basic Information</h3>
              <div className="space-y-2">
                <p>
                  <span className="font-semibold">Title:</span> {metadata.title}
                </p>
                <p>
                  <span className="font-semibold">Channel:</span>{" "}
                  {metadata.channelName}
                </p>
                <p>
                  <span className="font-semibold">Duration:</span>{" "}
                  {metadata.duration}
                </p>
                <p>
                  <span className="font-semibold">Video ID:</span>{" "}
                  {metadata.videoId}
                </p>
                {metadata.publishedAt && (
                  <p>
                    <span className="font-semibold">Published:</span>{" "}
                    {new Date(metadata.publishedAt).toLocaleDateString()}
                  </p>
                )}
                {metadata.viewCount && (
                  <p>
                    <span className="font-semibold">Views:</span>{" "}
                    {parseInt(metadata.viewCount).toLocaleString()}
                  </p>
                )}
                {metadata.likeCount && (
                  <p>
                    <span className="font-semibold">Likes:</span>{" "}
                    {parseInt(metadata.likeCount).toLocaleString()}
                  </p>
                )}
              </div>
            </div>

            <div className="bg-gray-50 p-4 rounded shadow">
              <h3 className="font-medium text-lg mb-2">Description</h3>
              <div className="max-h-60 overflow-y-auto">
                <p className="whitespace-pre-wrap">
                  {showFullDescription
                    ? metadata.fullDescription
                    : metadata.description}
                </p>
                {metadata.descriptionTruncated && (
                  <button
                    onClick={() => setShowFullDescription(!showFullDescription)}
                    className="mt-2 text-blue-500 hover:text-blue-700 text-sm font-medium"
                  >
                    {showFullDescription ? "Show less" : "Show more"}
                  </button>
                )}
              </div>
            </div>
          </div>

          {metadata.thumbnails && (
            <div className="bg-gray-50 p-4 rounded shadow">
              <h3 className="font-medium text-lg mb-2">Thumbnails</h3>
              <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
                {Object.entries(metadata.thumbnails).map(
                  ([key, thumb]: [string, any]) => (
                    <div key={key} className="text-center">
                      <img
                        src={thumb.url}
                        alt={`${key} thumbnail`}
                        className="mx-auto mb-2 rounded"
                      />
                      <p className="text-sm">
                        {key}: {thumb.width}x{thumb.height}
                      </p>
                    </div>
                  )
                )}
              </div>
            </div>
          )}

          <div className="mt-4 bg-gray-100 p-4 rounded overflow-auto max-h-96">
            <h3 className="font-medium text-lg mb-2">Raw JSON Data</h3>
            <pre className="text-xs">{JSON.stringify(metadata, null, 2)}</pre>
          </div>
        </div>
      )}
    </div>
  );
}
</file>

<file path="app/validate-transcript/page.tsx">
"use client";

import { useState } from "react";
import { useRouter } from "next/navigation";

export default function ValidateTranscript() {
  const [url, setUrl] = useState("");
  const [error, setError] = useState<string | null>(null);
  const [transcript, setTranscript] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);
  const router = useRouter();

  const validateTranscript = async () => {
    setLoading(true);
    setError(null);
    setTranscript(null);

    try {
      // Make a simple request to our chat API with a minimal question
      // This will test the transcript fetching functionality
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url,
          question:
            "Just testing the transcript. Please say 'Transcript fetched successfully!'",
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || "Failed to validate transcript");
      }

      setTranscript(data.answer);
    } catch (error) {
      console.error("Error:", error);
      const errorMessage =
        error instanceof Error
          ? error.message
          : "Failed to validate transcript";
      setError(errorMessage);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="p-6 max-w-4xl mx-auto">
      <h1 className="text-2xl font-bold mb-4">YouTube Transcript Validator</h1>
      <div className="mb-4">
        <input
          type="text"
          value={url}
          onChange={(e) => setUrl(e.target.value)}
          placeholder="Enter YouTube URL"
          className="w-full p-2 border rounded"
        />
      </div>
      <button
        onClick={validateTranscript}
        disabled={loading}
        className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-blue-300"
      >
        {loading ? "Validating..." : "Validate Transcript"}
      </button>

      {error && (
        <div className="mt-4 p-3 bg-red-100 text-red-700 rounded">{error}</div>
      )}

      {transcript && (
        <div className="mt-6">
          <h2 className="text-xl font-semibold mb-2">Transcript Result:</h2>
          <div className="p-4 bg-gray-50 rounded-lg border">{transcript}</div>
        </div>
      )}

      <div className="mt-4">
        <button
          onClick={() => router.push("/")}
          className="px-4 py-2 bg-gray-200 rounded"
        >
          Back to Home
        </button>
      </div>
    </div>
  );
}
</file>

<file path="app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --foreground-rgb: 0, 0, 0;
  --background-start-rgb: 214, 219, 220;
  --background-end-rgb: 255, 255, 255;
}

body {
  color: rgb(var(--foreground-rgb));
  background: linear-gradient(
      to bottom,
      transparent,
      rgb(var(--background-end-rgb))
    )
    rgb(var(--background-start-rgb));
}

@layer utilities {
  .prose {
    max-width: 65ch;
    line-height: 1.6;
  }

  .prose p {
    margin-bottom: 1.25em;
  }
}

/* Markdown styling */
pre {
  font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont,
    "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
  line-height: 1.6;
  font-size: 1rem;
  background-color: #f3f4f6;
  padding: 1em;
  border-radius: 0.5em;
  overflow-x: auto;
  margin: 1.5em 0;
}

pre code {
  background-color: transparent !important;
  padding: 0 !important;
  border-radius: 0 !important;
}

/* Enhanced Markdown Content Styling */
.markdown-content {
  font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont,
    "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
  line-height: 1.6;
  font-size: 1rem;
  color: #374151;
}

.markdown-content h1,
.markdown-content h2,
.markdown-content h3,
.markdown-content h4,
.markdown-content h5,
.markdown-content h6 {
  font-weight: 600;
  margin-top: 1.5em;
  margin-bottom: 0.75em;
  line-height: 1.3;
  color: #111827;
}

.markdown-content h1 {
  font-size: 1.875rem;
  margin-top: 0;
}

.markdown-content h2 {
  font-size: 1.5rem;
  border-bottom: 1px solid #e5e7eb;
  padding-bottom: 0.5em;
  margin-top: 2em;
}

.markdown-content h3 {
  font-size: 1.25rem;
}

.markdown-content p {
  margin-bottom: 1.25em;
}

.markdown-content ul,
.markdown-content ol {
  padding-left: 1.75em;
  margin: 1em 0;
}

.markdown-content li {
  margin-bottom: 0.5em;
  position: relative;
}

.markdown-content li p {
  margin-bottom: 0.5em;
}

.markdown-content code {
  font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
    "Liberation Mono", "Courier New", monospace;
  background-color: #f3f4f6;
  padding: 0.2em 0.4em;
  border-radius: 0.25em;
  font-size: 0.875em;
}

.markdown-content blockquote {
  border-left: 4px solid #e5e7eb;
  padding: 0.5em 1em;
  margin: 1.5em 0;
  background-color: #f9fafb;
  color: #4b5563;
}

.markdown-content a {
  color: #2563eb;
  text-decoration: underline;
  text-underline-offset: 2px;
}

.markdown-content a:hover {
  color: #1d4ed8;
}

.markdown-content hr {
  border: 0;
  border-top: 1px solid #e5e7eb;
  margin: 2em 0;
}

.markdown-content strong {
  font-weight: 600;
  color: #111827;
}

.markdown-content em {
  font-style: italic;
}

/* Timestamp styling */
.markdown-content p:has(code) {
  margin-top: 1.5em;
  font-weight: 500;
}

/* List item spacing */
.markdown-content ul li,
.markdown-content ol li {
  margin-bottom: 0.75em;
}

/* Nested lists */
.markdown-content ul ul,
.markdown-content ol ol,
.markdown-content ul ol,
.markdown-content ol ul {
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}

/* Table styling */
.markdown-content table {
  width: 100%;
  border-collapse: collapse;
  margin: 1.5em 0;
}

.markdown-content th,
.markdown-content td {
  padding: 0.75em;
  border: 1px solid #e5e7eb;
}

.markdown-content th {
  background-color: #f9fafb;
  font-weight: 600;
  text-align: left;
}

.markdown-content tr:nth-child(even) {
  background-color: #f9fafb;
}

/* Image styling */
.markdown-content img {
  max-width: 100%;
  height: auto;
  border-radius: 0.375em;
  margin: 1.5em 0;
}
</file>

<file path="app/page.tsx.backup">
"use client";

import React, { useState, useEffect } from "react";
import { ArrowPathIcon } from "@heroicons/react/24/solid";
import toast, { Toaster } from "react-hot-toast";
import Summary from "../components/Summary";
import Chat from "../components/Chat";
import Navbar from "../components/Navbar";
import PodcastHeader from "../components/PodcastHeader";
import { PodcastMetadataProvider } from "../components/PodcastMetadata";

export default function Home() {
  const [url, setUrl] = useState("");
  const [loading, setLoading] = useState(false);
  const [validating, setValidating] = useState(false);
  const [summary, setSummary] = useState<string | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [activeTab, setActiveTab] = useState<"summary" | "chat">("summary");
  const [isUrlValidated, setIsUrlValidated] = useState(false);
  const [isSummaryLoading, setIsSummaryLoading] = useState(false);
  const [isChatLoading, setIsChatLoading] = useState(false);

  // Function to validate YouTube URL format
  const isValidYoutubeUrl = (url: string): boolean => {
    const youtubeRegex = /^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.be)\/.+/;
    return youtubeRegex.test(url);
  };

  // Extract video ID from URL
  const extractVideoId = (url: string): string | null => {
    const match = url.match(
      /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
    );
    return match ? match[1] : null;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError(null);

    if (!isValidYoutubeUrl(url)) {
      toast.error("Please enter a valid YouTube URL");
      return;
    }

    const videoId = extractVideoId(url);
    if (!videoId) {
      toast.error("Could not extract video ID from URL");
      return;
    }

    setLoading(true);
    setIsSummaryLoading(true);
    setSummary(null);

    try {
      console.log("Submitting URL:", url);
      const response = await fetch("/api/summarize", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ url }),
      });

      const data = await response.json();
      console.log("Response:", data);

      if (!response.ok) {
        throw new Error(data.error || "Failed to generate summary");
      }

      setSummary(data.summary);
      setIsUrlValidated(true);
      toast.success("Summary generated successfully!");
    } catch (error) {
      console.error("Error:", error);
      const errorMessage =
        error instanceof Error ? error.message : "Failed to generate summary";
      setError(errorMessage);
      toast.error(errorMessage);
    } finally {
      setLoading(false);
      setIsSummaryLoading(false);
    }
  };

  const validateUrl = async () => {
    if (!isValidYoutubeUrl(url)) {
      toast.error("Please enter a valid YouTube URL");
      return;
    }

    const videoId = extractVideoId(url);
    if (!videoId) {
      toast.error("Could not extract video ID from URL");
      return;
    }

    setValidating(true);
    setIsChatLoading(true);
    setError(null);

    try {
      // Just check if the transcript exists
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url,
          question:
            "Just checking if the transcript exists. Please respond with 'Yes'.",
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || "Failed to validate URL");
      }

      setIsUrlValidated(true);
      setActiveTab("chat");
      toast.success("Podcast loaded successfully!");
    } catch (error) {
      console.error("Error:", error);
      const errorMessage =
        error instanceof Error ? error.message : "Failed to validate URL";
      setError(errorMessage);
      toast.error(errorMessage);
    } finally {
      setValidating(false);
      setIsChatLoading(false);
    }
  };

  const handleTabChange = (tab: "summary" | "chat") => {
    if (loading || validating) return;

    setActiveTab(tab);

    // If switching to chat and URL is not yet validated, validate it
    if (tab === "chat" && !isUrlValidated && url) {
      validateUrl();
    }

    // If switching to summary and no summary exists yet, generate it
    if (tab === "summary" && !summary && isUrlValidated) {
      setIsSummaryLoading(true);
      handleSubmit(new Event("submit") as any);
    }
  };

  // Handle URL input change
  const handleUrlChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setUrl(e.target.value);
    // Reset validation state when URL changes
    if (isUrlValidated) {
      setIsUrlValidated(false);
      setSummary(null);
    }
  };

  return (
    <div className="min-h-screen bg-[#f7f7ff]">
      <Navbar />
      <Toaster position="bottom-right" />

      <div className="max-w-7xl mx-auto px-4">
        <div className="pt-8 pb-16 md:pt-12 md:pb-24 text-center">
          <h1 className="text-5xl md:text-6xl font-bold text-purple-700 mb-6">
            Transform Podcasts into
            <br />
            Interactive Conversations
          </h1>
          <p className="text-lg text-gray-600 max-w-3xl mx-auto mb-10">
            Paste any podcast URL and let AI create summaries and engage in
            meaningful conversations about the content
          </p>

          <div className="max-w-3xl mx-auto bg-white p-8 rounded-2xl shadow-md">
            <div className="flex items-center mb-4">
              <div className="w-6 h-6 mr-2">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                  className="text-purple-600"
                >
                  <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
                  <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
                </svg>
              </div>
              <h2 className="text-xl font-semibold">Enter Podcast URL</h2>
            </div>

            <form onSubmit={handleSubmit}>
              <div className="flex flex-col gap-4">
                <div className="flex flex-col md:flex-row gap-2">
                  <input
                    id="youtube-url"
                    type="text"
                    value={url}
                    onChange={handleUrlChange}
                    placeholder="https://podcast-url.com/episode"
                    className="flex-1 p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-purple-500"
                    disabled={loading || validating}
                    aria-label="YouTube URL"
                  />
                  <button
                    type="submit"
                    disabled={loading || validating || !url.trim()}
                    className="px-6 py-3 bg-purple-600 text-white rounded-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center"
                    aria-label={loading ? "Processing..." : "Analyze"}
                  >
                    {loading ? (
                      <div className="flex items-center">
                        <ArrowPathIcon className="w-5 h-5 animate-spin mr-2" />
                        <span>Processing...</span>
                      </div>
                    ) : (
                      <div className="flex items-center">
                        <svg
                          xmlns="http://www.w3.org/2000/svg"
                          viewBox="0 0 24 24"
                          fill="currentColor"
                          className="w-5 h-5 mr-2"
                        >
                          <path d="M18.375 2.25c-1.035 0-1.875.84-1.875 1.875v15.75c0 1.035.84 1.875 1.875 1.875h.75c1.035 0 1.875-.84 1.875-1.875V4.125c0-1.036-.84-1.875-1.875-1.875h-.75zM9.75 8.625c0-1.036.84-1.875 1.875-1.875h.75c1.036 0 1.875.84 1.875 1.875v11.25c0 1.035-.84 1.875-1.875 1.875h-.75c-1.036 0-1.875-.84-1.875-1.875V8.625zM3 13.125c0-1.036.84-1.875 1.875-1.875h.75c1.036 0 1.875.84 1.875 1.875v6.75c0 1.035-.84 1.875-1.875 1.875h-.75C3.84 21.75 3 20.91 3 19.875v-6.75z" />
                        </svg>
                        Analyze
                      </div>
                    )}
                  </button>
                </div>
                {error && (
                  <div className="text-red-600 text-sm p-2 bg-red-50 rounded">
                    Error: {error}
                  </div>
                )}
              </div>
            </form>
          </div>
        </div>

        {/* Feature Cards Section - only shown when no podcast summary is generated */}
        {!isUrlValidated && (
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8 max-w-7xl mx-auto px-4 pb-20">
            {/* Smart Summaries Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M12 6.042A8.967 8.967 0 006 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 016 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 016-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0018 18a8.967 8.967 0 00-6 2.292m0-14.25v14.25" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Smart Summaries
              </h3>
              <p className="text-gray-600">
                Get comprehensive summaries that capture the key points and
                insights from any podcast.
              </p>
            </div>

            {/* Interactive Chat Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M4.913 2.658c2.075-.27 4.19-.408 6.337-.408 2.147 0 4.262.139 6.337.408 1.922.25 3.291 1.861 3.405 3.727a4.403 4.403 0 00-1.032-.211 50.89 50.89 0 00-8.42 0c-2.358.196-4.04 2.19-4.04 4.434v4.286a4.47 4.47 0 002.433 3.984L7.28 21.53A.75.75 0 016 21v-4.03a48.527 48.527 0 01-1.087-.128C2.905 16.58 1.5 14.833 1.5 12.862V6.638c0-1.97 1.405-3.718 3.413-3.979z" />
                  <path d="M15.75 7.5c-1.376 0-2.739.057-4.086.169C10.124 7.797 9 9.103 9 10.609v4.285c0 1.507 1.128 2.814 2.67 2.94 1.243.102 2.5.157 3.768.165l2.782 2.781a.75.75 0 001.28-.53v-2.39l.33-.026c1.542-.125 2.67-1.433 2.67-2.94v-4.286c0-1.505-1.125-2.811-2.664-2.94A49.392 49.392 0 0015.75 7.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Interactive Chat
              </h3>
              <p className="text-gray-600">
                Ask questions about the podcast content and get detailed answers
                from our AI assistant.
              </p>
            </div>

            {/* Works Everywhere Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
                  <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Works Everywhere
              </h3>
              <p className="text-gray-600">
                Compatible with podcasts from Spotify, Apple Podcasts, YouTube,
                and many more platforms.
              </p>
            </div>

            {/* AI-Powered Insights Card */}
            <div className="bg-white p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M21.731 2.269a2.625 2.625 0 00-3.712 0l-1.157 1.157 3.712 3.712 1.157-1.157a2.625 2.625 0 000-3.712zM19.513 8.199l-3.712-3.712-8.4 8.4a5.25 5.25 0 00-1.32 2.214l-.8 2.685a.75.75 0 00.933.933l2.685-.8a5.25 5.25 0 002.214-1.32l8.4-8.4z" />
                  <path d="M5.25 5.25a3 3 0 00-3 3v10.5a3 3 0 003 3h10.5a3 3 0 003-3V13.5a.75.75 0 00-1.5 0v5.25a1.5 1.5 0 01-1.5 1.5H5.25a1.5 1.5 0 01-1.5-1.5V8.25a1.5 1.5 0 011.5-1.5h5.25a.75.75 0 000-1.5H5.25z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                AI-Powered Insights
              </h3>
              <p className="text-gray-600">
                Advanced AI analyzes podcasts to extract the most relevant
                information and context.
              </p>
            </div>
          </div>
        )}

        {isUrlValidated && (
          <div className="max-w-5xl mx-auto">
            <PodcastMetadataProvider videoUrl={url}>
              {(metadata, metadataLoading) => (
                <>
                  {metadata && (
                    <PodcastHeader
                      videoId={metadata.videoId}
                      title={metadata.title}
                      channelName={metadata.channelName}
                      duration={metadata.duration}
                      description={metadata.description}
                      onChatClick={() => handleTabChange("chat")}
                      activeTab={activeTab}
                    />
                  )}

                  <div className="bg-white rounded-lg shadow-md mb-8">
                    <div className="flex border-b">
                      <button
                        onClick={() => handleTabChange("summary")}
                        className={`px-4 py-3 font-medium ${
                          activeTab === "summary"
                            ? "text-purple-600 border-b-2 border-purple-600"
                            : "text-gray-500 hover:text-gray-700"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Summary tab"
                        aria-selected={activeTab === "summary"}
                        role="tab"
                      >
                        Summary{" "}
                        {isSummaryLoading && (
                          <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                        )}
                      </button>
                      <button
                        onClick={() => handleTabChange("chat")}
                        className={`px-4 py-3 font-medium ${
                          activeTab === "chat"
                            ? "text-purple-600 border-b-2 border-purple-600"
                            : "text-gray-500 hover:text-gray-700"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Chat Assistant tab"
                        aria-selected={activeTab === "chat"}
                        role="tab"
                      >
                        Chat Assistant{" "}
                        {isChatLoading && (
                          <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                        )}
                      </button>
                    </div>

                    <div className="flex border-b space-x-8 px-4">
                      <button
                        onClick={() => handleTabChange("summary")}
                        className={`pt-4 pb-3 font-medium text-base ${
                          activeTab === "summary"
                            ? "text-purple-600 border-b-2 border-purple-600"
                            : "text-gray-500 hover:text-gray-700"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Summary tab"
                        aria-selected={activeTab === "summary"}
                        role="tab"
                      >
                        <div className="flex items-center">
                          <span>Summary</span>
                          {isSummaryLoading && (
                            <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                          )}
                        </div>
                      </button>
                      <button
                        onClick={() => handleTabChange("chat")}
                        className={`pt-4 pb-3 font-medium text-base ${
                          activeTab === "chat"
                            ? "text-purple-600 border-b-2 border-purple-600"
                            : "text-gray-500 hover:text-gray-700"
                        }`}
                        disabled={loading || validating}
                        aria-label="Switch to Chat Assistant tab"
                        aria-selected={activeTab === "chat"}
                        role="tab"
                      >
                        <div className="flex items-center">
                          <span>Chat Assistant</span>
                          {isChatLoading && (
                            <span className="ml-2 inline-block w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin"></span>
                          )}
                        </div>
                      </button>
                    </div>

                    <div
                      role="tabpanel"
                      aria-label="Tab Content"
                      className="p-8"
                    >
                      {activeTab === "summary" && (
                        <Summary summary={summary || ""} videoUrl={url} />
                      )}
                      {activeTab === "chat" && <Chat videoUrl={url} />}
                    </div>
                  </div>
                </>
              )}
            </PodcastMetadataProvider>
          </div>
        )}
      </div>
    </div>
  );
}
</file>

<file path="components/ErrorBoundary.tsx">
"use client";

import React, { Component, ErrorInfo, ReactNode } from "react";

interface Props {
  children: ReactNode;
  fallback?: ReactNode;
}

interface State {
  hasError: boolean;
  error: Error | null;
}

class ErrorBoundary extends Component<Props, State> {
  constructor(props: Props) {
    super(props);
    this.state = {
      hasError: false,
      error: null,
    };
  }

  static getDerivedStateFromError(error: Error): State {
    return {
      hasError: true,
      error,
    };
  }

  componentDidCatch(error: Error, errorInfo: ErrorInfo): void {
    console.error("Error caught by ErrorBoundary:", error, errorInfo);
  }

  render(): ReactNode {
    if (this.state.hasError) {
      if (this.props.fallback) {
        return this.props.fallback;
      }

      return (
        <div className="min-h-screen flex items-center justify-center bg-gray-50 p-4">
          <div className="bg-white p-8 rounded-lg shadow-md max-w-md w-full">
            <h2 className="text-2xl font-bold text-red-600 mb-4">
              Something went wrong
            </h2>
            <p className="text-gray-700 mb-4">
              We're sorry, but there was an error processing your request.
              Please try again later.
            </p>
            <div className="bg-gray-100 p-3 rounded text-sm text-gray-800 font-mono overflow-auto max-h-32 mb-4">
              {this.state.error?.message || "Unknown error"}
            </div>
            <button
              onClick={() => window.location.reload()}
              className="w-full py-2 px-4 bg-blue-600 text-white rounded hover:bg-blue-700 transition-colors"
            >
              Reload Page
            </button>
          </div>
        </div>
      );
    }

    return this.props.children;
  }
}

export default ErrorBoundary;
</file>

<file path="components/PodcastHeader.tsx">
import React, { useState } from "react";
import {
  ClockIcon,
  ChatBubbleLeftRightIcon,
  ShareIcon,
  EyeIcon,
  HandThumbUpIcon,
  CalendarIcon,
} from "@heroicons/react/24/outline";

interface PodcastHeaderProps {
  videoId: string;
  title: string;
  channelName: string;
  duration: string;
  viewCount?: string | null;
  likeCount?: string | null;
  publishedAt?: string | null;
  onChatClick: () => void;
  activeTab: "summary" | "chat";
}

const PodcastHeader: React.FC<PodcastHeaderProps> = ({
  videoId,
  title,
  channelName,
  duration,
  viewCount,
  likeCount,
  publishedAt,
  onChatClick,
  activeTab,
}) => {
  // Use the highest quality thumbnail available (maxresdefault is best quality)
  // With fallback to hqdefault if maxresdefault isn't available
  const thumbnailUrl = `https://i.ytimg.com/vi/${videoId}/maxresdefault.jpg`;
  const fallbackThumbnailUrl = `https://i.ytimg.com/vi/${videoId}/hqdefault.jpg`;
  const [imgSrc, setImgSrc] = useState(thumbnailUrl);

  // Format the published date
  const formatDate = (dateString: string | null) => {
    if (!dateString) return "Unknown date";

    const date = new Date(dateString);
    return date.toLocaleDateString("en-US", {
      year: "numeric",
      month: "long",
      day: "numeric",
    });
  };

  const handleShare = () => {
    if (navigator.share) {
      navigator
        .share({
          title: title,
          text: `Check out this podcast: ${title}`,
          url: `https://www.youtube.com/watch?v=${videoId}`,
        })
        .catch((err) => console.error("Error sharing:", err));
    } else {
      const url = `https://www.youtube.com/watch?v=${videoId}`;
      navigator.clipboard.writeText(url);
      alert("Link copied to clipboard!");
    }
  };

  return (
    <div className="bg-white rounded-xl shadow-md overflow-hidden mb-6">
      <div className="md:flex">
        {/* Fixed width container that matches 16:9 aspect ratio at 420x240 */}
        <div className="md:w-[420px] md:flex-shrink-0 relative">
          {/* Mobile: Dynamic 16:9 aspect ratio with padding trick */}
          {/* Desktop: Fixed height matching 16:9 ratio of width */}
          <div className="w-full pt-[56.25%] md:pt-0 md:h-[236px]">
            <img
              className="absolute inset-0 w-full h-full object-cover"
              src={imgSrc}
              alt={title}
              onError={() => setImgSrc(fallbackThumbnailUrl)}
            />
          </div>
        </div>
        <div className="p-6 flex flex-col justify-between w-full max-w-full">
          <div>
            <p className="text-sm text-purple-600 font-semibold uppercase tracking-wide">
              {channelName}
            </p>
            <h1 className="text-2xl font-bold text-gray-900 mt-1 mb-4">
              {title}
            </h1>

            {/* Metadata stats */}
            <div className="grid grid-cols-1 md:grid-cols-2 gap-y-2 gap-x-4 mb-4">
              <div className="flex items-center text-gray-600">
                <ClockIcon className="h-5 w-5 mr-1.5 text-gray-500" />
                <span>{duration}</span>
              </div>

              {publishedAt && (
                <div className="flex items-center text-gray-600">
                  <CalendarIcon className="h-5 w-5 mr-1.5 text-gray-500" />
                  <span>{formatDate(publishedAt)}</span>
                </div>
              )}

              {viewCount && (
                <div className="flex items-center text-gray-600">
                  <EyeIcon className="h-5 w-5 mr-1.5 text-gray-500" />
                  <span>{parseInt(viewCount).toLocaleString()} views</span>
                </div>
              )}

              {likeCount && (
                <div className="flex items-center text-gray-600">
                  <HandThumbUpIcon className="h-5 w-5 mr-1.5 text-gray-500" />
                  <span>{parseInt(likeCount).toLocaleString()} likes</span>
                </div>
              )}
            </div>
          </div>

          <div className="mt-4 flex gap-3">
            <button
              onClick={onChatClick}
              className={`flex items-center px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
                activeTab === "chat"
                  ? "bg-purple-600 text-white"
                  : "bg-purple-100 text-purple-700 hover:bg-purple-200"
              }`}
            >
              <ChatBubbleLeftRightIcon className="h-4 w-4 mr-2" />
              Chat About This
            </button>
            <button
              onClick={handleShare}
              className="flex items-center px-4 py-2 bg-gray-100 text-gray-700 rounded-lg text-sm font-medium hover:bg-gray-200 transition-colors"
            >
              <ShareIcon className="h-4 w-4 mr-2" />
              Share
            </button>
          </div>
        </div>
      </div>
    </div>
  );
};

export default PodcastHeader;
</file>

<file path="components/PodcastMetadata.tsx">
import React, { useEffect, useState } from "react";

export interface PodcastMetadata {
  title: string;
  channelName: string;
  duration: string;
  videoId: string;
  description?: string;
  fullDescription?: string;
  descriptionTruncated?: boolean;
  publishedAt?: string | null;
  viewCount?: string | null;
  likeCount?: string | null;
  thumbnails?: {
    [key: string]: {
      url: string;
      width: number;
      height: number;
    };
  } | null;
}

interface PodcastMetadataProviderProps {
  videoUrl: string;
  children: (
    metadata: PodcastMetadata | null,
    loading: boolean
  ) => React.ReactNode;
}

const extractVideoId = (url: string): string | null => {
  const match = url.match(
    /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
  );
  return match ? match[1] : null;
};

const formatDuration = (seconds: number): string => {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);

  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, "0")}:${secs
      .toString()
      .padStart(2, "0")}`;
  }

  return `${minutes}:${secs.toString().padStart(2, "0")}`;
};

export const PodcastMetadataProvider: React.FC<
  PodcastMetadataProviderProps
> = ({ videoUrl, children }) => {
  const [metadata, setMetadata] = useState<PodcastMetadata | null>(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchMetadata = async () => {
      try {
        setLoading(true);
        const videoId = extractVideoId(videoUrl);

        if (!videoId) {
          throw new Error("Invalid YouTube URL");
        }

        // Call our metadata API endpoint
        const response = await fetch("/api/podcast-metadata", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            url: videoUrl,
            includeFull: true, // Always request full description
          }),
        });

        if (!response.ok) {
          const errorData = await response.json();
          throw new Error(errorData.error || "Failed to fetch metadata");
        }

        const data = await response.json();
        setMetadata(data.metadata);
      } catch (error) {
        console.error("Error fetching metadata:", error);

        // Fallback metadata using the video ID
        const videoId = extractVideoId(videoUrl);
        if (videoId) {
          setMetadata({
            title: "YouTube Podcast",
            channelName: "Unknown Channel",
            duration: "00:00",
            videoId: videoId,
            description: "No description available for this podcast.",
            fullDescription: "No description available for this podcast.",
            descriptionTruncated: false,
          });
        } else {
          setMetadata(null);
        }
      } finally {
        setLoading(false);
      }
    };

    if (videoUrl) {
      fetchMetadata();
    }
  }, [videoUrl]);

  return <>{children(metadata, loading)}</>;
};
</file>

<file path="lib/supabase/client.ts">
import { createBrowserClient } from "@supabase/ssr";

export function createClient() {
  // Create a supabase client on the browser with project's credentials
  return createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  );
}
</file>

<file path="lib/supabase/server.ts">
import { createServerClient, type CookieOptions } from "@supabase/ssr";
import { cookies } from "next/headers";

export function createClient() {
  const cookieStore = cookies();

  return createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return cookieStore.get(name)?.value;
        },
        set(name: string, value: string, options: CookieOptions) {
          try {
            cookieStore.set({ name, value, ...options });
          } catch (error) {
            // The `set` method was called from a Server Component.
            // This can be ignored if you have middleware refreshing
            // user sessions.
          }
        },
        remove(name: string, options: CookieOptions) {
          try {
            cookieStore.set({ name, value: "", ...options });
          } catch (error) {
            // The `delete` method was called from a Server Component.
            // This can be ignored if you have middleware refreshing
            // user sessions.
          }
        },
      },
    }
  );
}
</file>

<file path="lib/supabaseClient.ts">
import { createClient } from "@supabase/supabase-js";

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

if (!supabaseUrl || !supabaseAnonKey) {
  throw new Error("Missing Supabase URL or Anon Key in environment variables");
}

export const supabase = createClient(supabaseUrl, supabaseAnonKey);
</file>

<file path="public/create-screenshot.html">
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>App Screenshot Generator</title>
    <style>
      body {
        margin: 0;
        padding: 0;
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
          Roboto, "Helvetica Neue", Arial, sans-serif;
      }
      .app-container {
        width: 1200px;
        height: 800px;
        overflow: hidden;
        background-color: #f7f7ff;
        position: relative;
      }
      .app-header {
        background-color: white;
        padding: 20px;
        border-bottom: 1px solid #e5e7eb;
        display: flex;
        align-items: center;
      }
      .app-logo {
        width: 40px;
        height: 40px;
        background-color: #8b5cf6;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 12px;
      }
      .app-title {
        font-weight: 700;
        font-size: 22px;
        color: #8b5cf6;
      }
      .content {
        max-width: 1000px;
        margin: 0 auto;
        padding: 30px 20px;
      }
      .podcast-card {
        background-color: white;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -1px rgba(0, 0, 0, 0.06);
        overflow: hidden;
      }
      .podcast-header {
        display: flex;
        padding: 24px;
        border-bottom: 1px solid #e5e7eb;
      }
      .podcast-thumbnail {
        width: 180px;
        height: 100px;
        background-color: #e0e7ff;
        border-radius: 8px;
        margin-right: 20px;
        flex-shrink: 0;
        display: flex;
        align-items: center;
        justify-content: center;
      }
      .podcast-info {
        flex: 1;
      }
      .podcast-title {
        font-size: 20px;
        font-weight: 600;
        margin-bottom: 8px;
        color: #1f2937;
      }
      .podcast-author {
        font-size: 16px;
        color: #6b7280;
        margin-bottom: 12px;
      }
      .podcast-metadata {
        display: flex;
        gap: 16px;
        font-size: 14px;
        color: #9ca3af;
      }
      .tabs {
        display: flex;
        border-bottom: 1px solid #e5e7eb;
      }
      .tab {
        flex: 1;
        padding: 16px;
        text-align: center;
        font-weight: 500;
        cursor: pointer;
      }
      .tab.active {
        color: #8b5cf6;
        border-bottom: 2px solid #8b5cf6;
        background-color: #f5f3ff;
      }
      .tab-content {
        padding: 24px;
      }
      .chat-container {
        display: flex;
        flex-direction: column;
        height: 500px;
      }
      .chat-messages {
        flex: 1;
        overflow-y: auto;
        padding: 16px;
        display: flex;
        flex-direction: column;
        gap: 16px;
      }
      .message-pair {
        display: flex;
        flex-direction: column;
        gap: 16px;
        margin-bottom: 24px;
      }
      .message {
        max-width: 85%;
        border-radius: 12px;
        overflow: hidden;
      }
      .message-avatar {
        width: 36px;
        height: 36px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 12px;
        flex-shrink: 0;
      }
      .user-avatar {
        background-color: #e0e7ff;
        color: #4338ca;
      }
      .ai-avatar {
        background-color: #ede9fe;
        color: #8b5cf6;
      }
      .message-content {
        flex: 1;
      }
      .message-wrapper {
        display: flex;
        align-items: flex-start;
      }
      .user-message .message-content {
        background-color: #f3f4f6;
        padding: 16px;
        border-radius: 12px;
        color: #1f2937;
      }
      .ai-message .message-content {
        background-color: #ede9fe;
        padding: 16px;
        border-radius: 12px;
        color: #1f2937;
      }
      .chat-input {
        display: flex;
        padding: 16px;
        border-top: 1px solid #e5e7eb;
      }
      .chat-input input {
        flex: 1;
        padding: 12px 16px;
        border: 1px solid #d1d5db;
        border-radius: 8px;
        margin-right: 12px;
        font-size: 14px;
      }
      .chat-input button {
        padding: 0 16px;
        background-color: #8b5cf6;
        color: white;
        border: none;
        border-radius: 8px;
        font-weight: 500;
      }
      .message-list {
        margin: 0;
        padding-left: 20px;
      }
      .message-list li {
        margin-bottom: 10px;
      }
    </style>
  </head>
  <body>
    <div class="app-container">
      <div class="app-header">
        <div class="app-logo">
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="24"
            height="24"
            viewBox="0 0 24 24"
            fill="white"
          >
            <path
              d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z"
            />
            <path
              d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z"
            />
          </svg>
        </div>
        <div class="app-title">PodAI</div>
      </div>

      <div class="content">
        <div class="podcast-card">
          <div class="podcast-header">
            <div class="podcast-thumbnail">
              <svg
                xmlns="http://www.w3.org/2000/svg"
                width="32"
                height="32"
                viewBox="0 0 24 24"
                fill="#8b5cf6"
              >
                <path
                  d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z"
                />
                <path
                  d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z"
                />
              </svg>
            </div>
            <div class="podcast-info">
              <div class="podcast-title">
                The AI Economy: Future Trends with Dr. Sophia Chen
              </div>
              <div class="podcast-author">Economics Insights Podcast</div>
              <div class="podcast-metadata">
                <span>58:45</span>
                <span>1.2M views</span>
                <span>87K likes</span>
                <span>June 10, 2023</span>
              </div>
            </div>
          </div>

          <div class="tabs">
            <div class="tab">Summary</div>
            <div class="tab active">Chat Assistant</div>
          </div>

          <div class="tab-content">
            <div class="chat-container">
              <div class="chat-messages">
                <div class="message-pair">
                  <div class="message-wrapper user-message">
                    <div class="message-avatar user-avatar">
                      <svg
                        xmlns="http://www.w3.org/2000/svg"
                        width="20"
                        height="20"
                        viewBox="0 0 24 24"
                        fill="currentColor"
                      >
                        <path
                          d="M18.685 19.097A9.723 9.723 0 0021.75 12c0-5.385-4.365-9.75-9.75-9.75S2.25 6.615 2.25 12a9.723 9.723 0 003.065 7.097A9.716 9.716 0 0012 21.75a9.716 9.716 0 006.685-2.653zm-12.54-1.285A7.486 7.486 0 0112 15a7.486 7.486 0 015.855 2.812A8.224 8.224 0 0112 20.25a8.224 8.224 0 01-5.855-2.438zM15.75 9a3.75 3.75 0 11-7.5 0 3.75 3.75 0 017.5 0z"
                        />
                      </svg>
                    </div>
                    <div class="message-content">
                      What were the main economic impacts discussed in the
                      podcast?
                    </div>
                  </div>

                  <div class="message-wrapper ai-message">
                    <div class="message-avatar ai-avatar">
                      <svg
                        xmlns="http://www.w3.org/2000/svg"
                        width="20"
                        height="20"
                        viewBox="0 0 24 24"
                        fill="currentColor"
                      >
                        <path
                          d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z"
                        />
                        <path
                          d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z"
                        />
                      </svg>
                    </div>
                    <div class="message-content">
                      <p>
                        The podcast highlighted three main economic impacts:
                      </p>
                      <ol class="message-list">
                        <li>
                          AI automation could increase global GDP by up to 14%
                          by 2030
                        </li>
                        <li>
                          Job market disruption with an estimated 15% of jobs
                          being redefined
                        </li>
                        <li>
                          New industries emerging that could create 97 million
                          new roles
                        </li>
                      </ol>
                      <p>
                        Dr. Chen specifically emphasized the need for reskilling
                        programs as this transition occurs.
                      </p>
                    </div>
                  </div>
                </div>

                <div class="message-wrapper user-message">
                  <div class="message-avatar user-avatar">
                    <svg
                      xmlns="http://www.w3.org/2000/svg"
                      width="20"
                      height="20"
                      viewBox="0 0 24 24"
                      fill="currentColor"
                    >
                      <path
                        d="M18.685 19.097A9.723 9.723 0 0021.75 12c0-5.385-4.365-9.75-9.75-9.75S2.25 6.615 2.25 12a9.723 9.723 0 003.065 7.097A9.716 9.716 0 0012 21.75a9.716 9.716 0 006.685-2.653zm-12.54-1.285A7.486 7.486 0 0112 15a7.486 7.486 0 015.855 2.812A8.224 8.224 0 0112 20.25a8.224 8.224 0 01-5.855-2.438zM15.75 9a3.75 3.75 0 11-7.5 0 3.75 3.75 0 017.5 0z"
                      />
                    </svg>
                  </div>
                  <div class="message-content">
                    What sectors did she mention would be most affected?
                  </div>
                </div>
              </div>

              <div class="chat-input">
                <input
                  type="text"
                  placeholder="Ask a question about the podcast content..."
                />
                <button>
                  <svg
                    xmlns="http://www.w3.org/2000/svg"
                    width="20"
                    height="20"
                    viewBox="0 0 24 24"
                    fill="none"
                    stroke="currentColor"
                    stroke-width="2"
                    stroke-linecap="round"
                    stroke-linejoin="round"
                  >
                    <line x1="22" y1="2" x2="11" y2="13"></line>
                    <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
                  </svg>
                </button>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Instructions -->
    <div style="margin: 20px; font-family: sans-serif">
      <h1>App Screenshot Generator</h1>
      <p>
        Take a screenshot of the above app interface and save it as
        "app-screenshot.png" in the public directory.
      </p>
      <p>
        On macOS: Press Command + Shift + 4, then select the app interface area.
      </p>
      <p>
        On Windows: Use the Snipping Tool or press Windows + Shift + S to
        capture the interface.
      </p>
    </div>
  </body>
</html>
</file>

<file path="public/README.md">
# App Screenshot Instructions

This directory contains a file `create-screenshot.html` that can be used to generate a screenshot for the landing page.

## How to generate the screenshot:

1. Open the `create-screenshot.html` file in a web browser
2. Take a screenshot of the application interface (not including the instructions)
3. Save the screenshot as `app-screenshot.png` in this directory (public/)

## Taking a screenshot on different operating systems:

- **macOS**: Press `Command + Shift + 4`, then select the area you want to capture
- **Windows**: Use the Snipping Tool or press `Windows + Shift + S` to capture a specific area
- **Linux**: Use a tool like GNOME Screenshot or press `PrtScn` key

The screenshot will be used on the landing page to show visitors what the application looks like.
</file>

<file path=".gitignore">
# dependencies
/node_modules
/.pnp
.pnp.js

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

# IDE
.idea/
.vscode/
*.swp
*.swo
</file>

<file path="middleware.ts">
import { createServerClient, type CookieOptions } from "@supabase/ssr";
import { NextResponse, type NextRequest } from "next/server";

export async function middleware(request: NextRequest) {
  let response = NextResponse.next({
    request: {
      headers: request.headers,
    },
  });

  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return request.cookies.get(name)?.value;
        },
        set(name: string, value: string, options: CookieOptions) {
          request.cookies.set({
            name,
            value,
            ...options,
          });
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          });
          response.cookies.set({
            name,
            value,
            ...options,
          });
        },
        remove(name: string, options: CookieOptions) {
          request.cookies.set({
            name,
            value: "",
            ...options,
          });
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          });
          response.cookies.set({
            name,
            value: "",
            ...options,
          });
        },
      },
    }
  );

  const {
    data: { user },
    error,
  } = await supabase.auth.getUser();

  if (error && error.message !== "Auth session missing!") {
    console.error("[Middleware] Error getting user:", error.message);
  }

  // Protect the /dashboard route
  if (!user && request.nextUrl.pathname.startsWith("/dashboard")) {
    return NextResponse.redirect(new URL("/", request.url));
  }

  // Redirect authenticated users from the landing page to the dashboard
  if (user && request.nextUrl.pathname === "/") {
    return NextResponse.redirect(new URL("/dashboard", request.url));
  }

  return response;
}

export const config = {
  matcher: [
    /*
     * Match all request paths except for the ones starting with:
     * - _next/static (static files)
     * - _next/image (image optimization files)
     * - favicon.ico (favicon file)
     * Feel free to modify this pattern to include more paths.
     */
    "/((?!_next/static|_next/image|favicon.ico|.*\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)",
  ],
};
</file>

<file path="postcss.config.js">
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};
</file>

<file path="supabaseplan.md">
# Supabase Google Authentication Implementation Plan

## 1. Set up Supabase project

- [x] Create a new Supabase project (Used existing: PodAI, ID: wjkqshfnsqkmhmqsiaol)
- [ ] Configure database schema for user authentication (Using default `auth.users` for now)
- [ ] Set up Row Level Security (RLS) policies (Will implement when user-specific tables are added)

## 2. Configure Google OAuth credentials

- [x] Create a Google Cloud project
- [x] Set up OAuth consent screen
- [x] Generate OAuth client ID and secret
- [x] Add authorized redirect URIs for your application (`https://wjkqshfnsqkmhmqsiaol.supabase.co/auth/v1/callback`)

## 3. Configure Supabase Auth with Google provider

- [x] Add Google OAuth credentials to Supabase Auth settings
- [x] Configure Supabase redirect URLs (Verified match)

## 4. Implement frontend authentication flow

- [x] Install Supabase client library (`@supabase/ssr` and `@supabase/supabase-js`)
- [x] Create authentication components (Updated `Navbar.tsx` & `app/page.tsx` with state, sign-in/out)
- [x] Implement sign-in, sign-out, and session management (Done via `Navbar.tsx`, `app/page.tsx` and `middleware.ts`)
- [x] Set up protected routes for authenticated users (Done via `middleware.ts`)

## 5. Update application to use authentication context

- [x] Modify existing components to respect authentication state (`app/page.tsx`, `middleware.ts`)
- [x] Ensure dashboard is only accessible to authenticated users (Done via `middleware.ts`)
- [x] Redirect unauthenticated users to landing page (Done via `middleware.ts`)

## 6. Test authentication flow

- [x] Verify sign-in process works correctly
- [x] Test session persistence
- [x] Ensure protected routes are properly secured
</file>

<file path="app/layout.tsx">
import type { Metadata } from "next";
import { Poppins } from "next/font/google";
import "./globals.css";
import ErrorBoundary from "../components/ErrorBoundary";

const poppins = Poppins({
  weight: ["400", "500", "600", "700"],
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "YouTube AI Podcast Assistant",
  description: "Summarize and chat with YouTube podcasts using AI",
  keywords: "YouTube, podcast, AI, summarizer, chat, assistant, transcript",
  authors: [{ name: "Your Name" }],
  viewport: "width=device-width, initial-scale=1",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en" suppressHydrationWarning>
      <body className={poppins.className}>
        <ErrorBoundary>{children}</ErrorBoundary>
      </body>
    </html>
  );
}
</file>

<file path="app/page.tsx">
"use client";

import React, { useEffect, useState } from "react";
import { useRouter } from "next/navigation";
import Link from "next/link";
import Image from "next/image";
import { createClient } from "@/lib/supabase/client";

// NoSSR wrapper component to prevent hydration mismatches
function NoSSR({ children }: { children: React.ReactNode }) {
  const [mounted, setMounted] = useState(false);

  useEffect(() => {
    setMounted(true);
  }, []);

  return mounted ? <>{children}</> : null;
}

export default function LandingPage() {
  const router = useRouter();
  const [mounted, setMounted] = useState(false);
  const [loading, setLoading] = useState(false);
  const supabase = createClient();

  useEffect(() => {
    setMounted(true);
  }, []);

  const handleNavigation = (path: string) => {
    if (mounted) {
      router.push(path);
    }
  };

  const handleSignIn = async () => {
    setLoading(true);
    const { error } = await supabase.auth.signInWithOAuth({
      provider: "google",
      options: {
        redirectTo: `${window.location.origin}/auth/callback`,
      },
    });
    if (error) {
      console.error("Error signing in:", error.message);
    }
  };

  return (
    <div className="min-h-screen bg-[#f7f7ff]">
      {/* Navigation */}
      <nav className="bg-white shadow-sm">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between h-16">
            <div className="flex items-center">
              <div className="text-purple-700 font-bold text-xl">
                YouTube AI Podcast Assistant
              </div>
            </div>
            <div className="flex items-center space-x-4">
              <button
                onClick={handleSignIn}
                disabled={loading}
                className="px-4 py-2 bg-purple-600 text-white rounded-lg hover:bg-purple-700 disabled:opacity-50"
              >
                {loading ? "Signing In..." : "Sign In"}
              </button>
            </div>
          </div>
        </div>
      </nav>

      {/* Hero Section - Two Column Layout */}
      <div className="max-w-7xl mx-auto px-4 pt-16 pb-12 sm:pt-24 sm:pb-20">
        <div className="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
          {/* Left Column - Text Content */}
          <div className="text-left">
            <h1 className="text-4xl md:text-5xl lg:text-6xl font-bold text-purple-700 mb-6">
              Transform Podcasts into Interactive Conversations
            </h1>
            <p className="text-lg text-gray-600 mb-10">
              Paste any podcast URL and let AI create summaries and engage in
              meaningful conversations about the content
            </p>
            <div className="flex flex-col sm:flex-row gap-4 sm:gap-6">
              <button
                onClick={handleSignIn}
                disabled={loading}
                className="px-8 py-3 bg-purple-600 text-white rounded-lg hover:bg-purple-700 text-lg font-medium disabled:opacity-50"
              >
                {loading ? "Redirecting..." : "Get Started"}
              </button>
              <a
                href="#how-it-works"
                className="px-8 py-3 bg-purple-100 text-purple-700 rounded-lg hover:bg-purple-200 text-lg font-medium text-center"
              >
                Learn More
              </a>
            </div>
          </div>

          {/* Right Column - Screenshot */}
          <div className="relative flex justify-center md:justify-end">
            <div
              className="relative w-full rounded-xl shadow-2xl overflow-hidden border-8 border-white"
              style={{ maxHeight: "80vh" }}
            >
              <div
                style={{
                  position: "relative",
                  width: "100%",
                  paddingTop: "64.3%",
                }}
              >
                <NoSSR>
                  <Image
                    src="/app-screenshot-new.png"
                    alt="AI chat interface analyzing economic impacts from a podcast"
                    fill
                    sizes="(max-width: 768px) 100vw, 50vw"
                    priority
                    className="object-cover rounded-lg"
                    style={{ objectFit: "cover" }}
                  />
                </NoSSR>
              </div>
            </div>
          </div>
        </div>
      </div>

      {/* Feature Cards Section */}
      <div className="bg-white py-16">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="text-center mb-12">
            <h2 className="text-3xl font-bold text-gray-900">Key Features</h2>
            <p className="mt-4 text-lg text-gray-600">
              Everything you need to get more from your podcast listening
              experience
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
            {/* Smart Summaries Card */}
            <div className="bg-[#f7f7ff] p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M12 6.042A8.967 8.967 0 006 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 016 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 016-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0018 18a8.967 8.967 0 00-6 2.292m0-14.25v14.25" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Smart Summaries
              </h3>
              <p className="text-gray-600">
                Get comprehensive summaries that capture the key points and
                insights from any podcast.
              </p>
            </div>

            {/* Interactive Chat Card */}
            <div className="bg-[#f7f7ff] p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M4.913 2.658c2.075-.27 4.19-.408 6.337-.408 2.147 0 4.262.139 6.337.408 1.922.25 3.291 1.861 3.405 3.727a4.403 4.403 0 00-1.032-.211 50.89 50.89 0 00-8.42 0c-2.358.196-4.04 2.19-4.04 4.434v4.286a4.47 4.47 0 002.433 3.984L7.28 21.53A.75.75 0 016 21v-4.03a48.527 48.527 0 01-1.087-.128C2.905 16.58 1.5 14.833 1.5 12.862V6.638c0-1.97 1.405-3.718 3.413-3.979z" />
                  <path d="M15.75 7.5c-1.376 0-2.739.057-4.086.169C10.124 7.797 9 9.103 9 10.609v4.285c0 1.507 1.128 2.814 2.67 2.94 1.243.102 2.5.157 3.768.165l2.782 2.781a.75.75 0 001.28-.53v-2.39l.33-.026c1.542-.125 2.67-1.433 2.67-2.94v-4.286c0-1.505-1.125-2.811-2.664-2.94A49.392 49.392 0 0015.75 7.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Interactive Chat
              </h3>
              <p className="text-gray-600">
                Ask questions about the podcast content and get detailed answers
                from our AI assistant.
              </p>
            </div>

            {/* Works Everywhere Card */}
            <div className="bg-[#f7f7ff] p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
                  <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Works Everywhere
              </h3>
              <p className="text-gray-600">
                Compatible with podcasts from YouTube and many more platforms.
              </p>
            </div>

            {/* AI-Powered Insights Card */}
            <div className="bg-[#f7f7ff] p-8 rounded-2xl shadow-md flex flex-col items-start h-full">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  className="h-8 w-8 text-purple-600"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                >
                  <path d="M21.731 2.269a2.625 2.625 0 00-3.712 0l-1.157 1.157 3.712 3.712 1.157-1.157a2.625 2.625 0 000-3.712zM19.513 8.199l-3.712-3.712-8.4 8.4a5.25 5.25 0 00-1.32 2.214l-.8 2.685a.75.75 0 00.933.933l2.685-.8a5.25 5.25 0 002.214-1.32l8.4-8.4z" />
                  <path d="M5.25 5.25a3 3 0 00-3 3v10.5a3 3 0 003 3h10.5a3 3 0 003-3V13.5a.75.75 0 00-1.5 0v5.25a1.5 1.5 0 01-1.5 1.5H5.25a1.5 1.5 0 01-1.5-1.5V8.25a1.5 1.5 0 011.5-1.5h5.25a.75.75 0 000-1.5H5.25z" />
                </svg>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                AI-Powered Insights
              </h3>
              <p className="text-gray-600">
                Advanced AI analyzes podcasts to extract the most relevant
                information and context.
              </p>
            </div>
          </div>
        </div>
      </div>

      {/* How It Works Section */}
      <div id="how-it-works" className="py-16">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="text-center mb-12">
            <h2 className="text-3xl font-bold text-gray-900">How It Works</h2>
            <p className="mt-4 text-lg text-gray-600">
              Simple process, powerful results
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-3 gap-8">
            {/* Step 1 */}
            <div className="text-center">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5 mx-auto">
                <span className="text-2xl font-bold text-purple-600">1</span>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Paste YouTube URL
              </h3>
              <p className="text-gray-600">
                Simply paste the URL of any YouTube podcast you want to analyze
              </p>
            </div>

            {/* Step 2 */}
            <div className="text-center">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5 mx-auto">
                <span className="text-2xl font-bold text-purple-600">2</span>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                AI Processes the Content
              </h3>
              <p className="text-gray-600">
                Our advanced AI analyzes the audio transcript to extract key
                information
              </p>
            </div>

            {/* Step 3 */}
            <div className="text-center">
              <div className="h-16 w-16 rounded-full bg-purple-100 flex items-center justify-center mb-5 mx-auto">
                <span className="text-2xl font-bold text-purple-600">3</span>
              </div>
              <h3 className="text-xl font-semibold text-gray-900 mb-3">
                Interact with Results
              </h3>
              <p className="text-gray-600">
                Get a comprehensive summary or chat with the AI about specific
                content
              </p>
            </div>
          </div>
        </div>
      </div>

      {/* CTA Section */}
      <div className="bg-purple-700 py-16">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
          <h2 className="text-3xl font-bold text-white mb-4">
            Ready to Unlock Podcast Insights?
          </h2>
          <p className="text-lg text-purple-200 mb-8">
            Start summarizing and chatting with your favorite podcasts today.
          </p>
          <button
            onClick={handleSignIn}
            disabled={loading}
            className="px-8 py-3 bg-white text-purple-700 rounded-lg hover:bg-gray-100 text-lg font-medium disabled:opacity-50"
          >
            {loading ? "Redirecting..." : "Get Started Now"}
          </button>
        </div>
      </div>

      {/* Footer */}
      <footer className="bg-[#f7f7ff] py-8">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center text-gray-500">
          &copy; {new Date().getFullYear()} YouTube AI Podcast Assistant. All
          rights reserved.
        </div>
      </footer>
    </div>
  );
}
</file>

<file path="components/Chat.tsx">
import React, { useState, useRef, useEffect } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import { toast } from "react-hot-toast";
import { PaperAirplaneIcon } from "@heroicons/react/24/outline";

interface Message {
  role: "user" | "assistant";
  content: string;
  timestamp?: Date;
}

interface ChatProps {
  videoUrl: string;
}

const Chat: React.FC<ChatProps> = ({ videoUrl }) => {
  const [input, setInput] = useState("");
  const [messages, setMessages] = useState<Message[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);

  // Scroll to bottom of chat when messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // Focus input field when component mounts
  useEffect(() => {
    if (!loading && inputRef.current) {
      inputRef.current.focus();
    }
  }, [loading]);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim() || loading) return;

    const userMessage: Message = {
      role: "user",
      content: input,
      timestamp: new Date(),
    };
    setMessages((prev) => [...prev, userMessage]);
    setInput("");
    setError(null);
    setLoading(true);

    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url: videoUrl,
          question: input,
          chatHistory: messages.map(({ role, content }) => ({ role, content })),
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || "Failed to get response");
      }

      const assistantMessage: Message = {
        role: "assistant",
        content: data.answer,
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, assistantMessage]);
    } catch (err) {
      console.error("Error:", err);
      const errorMessage =
        err instanceof Error ? err.message : "Failed to get response";
      setError(errorMessage);
      toast.error(`Error: ${errorMessage}`);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="bg-white rounded-lg flex flex-col h-full">
      <div className="flex-1 flex flex-col">
        <div
          className="flex-1 overflow-y-auto p-4 space-y-4 bg-gray-50"
          style={{ maxHeight: "calc(70vh - 130px)" }}
          aria-live="polite"
        >
          {messages.length === 0 ? (
            <div className="text-center text-gray-500 my-8 bg-white p-6 rounded-lg">
              <p className="font-medium text-gray-700 mb-3">
                Ask any question about this podcast
              </p>
              <p className="text-sm mb-3">For example:</p>
              <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
                {[
                  "What were the main topics discussed?",
                  "Summarize the key points about [specific topic]",
                  "What did the speaker say about [specific concept]?",
                  "What were the most interesting insights shared?",
                ].map((suggestion, index) => (
                  <button
                    key={index}
                    onClick={() => {
                      setInput(suggestion);
                      if (inputRef.current) inputRef.current.focus();
                    }}
                    className="text-sm text-left p-2 bg-purple-50 text-purple-700 rounded-md hover:bg-purple-100 transition-colors"
                  >
                    {suggestion}
                  </button>
                ))}
              </div>
            </div>
          ) : (
            messages.map((message, index) => (
              <div
                key={index}
                className={`flex ${
                  message.role === "user" ? "justify-end" : "justify-start"
                }`}
              >
                <div
                  className={`max-w-[80%] rounded-lg p-4 ${
                    message.role === "user"
                      ? "bg-purple-100 text-purple-900"
                      : "bg-white text-gray-800 border border-gray-100"
                  }`}
                >
                  <div className="prose prose-sm max-w-none">
                    <ReactMarkdown remarkPlugins={[remarkGfm]}>
                      {message.content}
                    </ReactMarkdown>
                  </div>
                  {message.timestamp && (
                    <div className="text-xs text-gray-500 mt-2 text-right">
                      {message.timestamp.toLocaleTimeString([], {
                        hour: "2-digit",
                        minute: "2-digit",
                      })}
                    </div>
                  )}
                </div>
              </div>
            ))
          )}
          {loading && (
            <div className="flex justify-start">
              <div className="max-w-[80%] rounded-lg p-4 bg-white border border-gray-100">
                <div className="flex items-center space-x-2">
                  <div
                    className="w-2 h-2 rounded-full bg-purple-400 animate-bounce"
                    style={{ animationDelay: "0ms" }}
                  ></div>
                  <div
                    className="w-2 h-2 rounded-full bg-purple-500 animate-bounce"
                    style={{ animationDelay: "150ms" }}
                  ></div>
                  <div
                    className="w-2 h-2 rounded-full bg-purple-600 animate-bounce"
                    style={{ animationDelay: "300ms" }}
                  ></div>
                </div>
              </div>
            </div>
          )}
          {error && (
            <div className="text-red-600 text-sm p-3 bg-red-50 rounded border border-red-200">
              Error: {error}
            </div>
          )}
          <div ref={messagesEndRef} />
        </div>
        <form onSubmit={handleSubmit} className="p-4 bg-white">
          <div className="flex items-center">
            <input
              type="text"
              ref={inputRef}
              value={input}
              onChange={(e) => setInput(e.target.value)}
              placeholder="Ask a question about this podcast..."
              className="flex-1 p-3 border border-gray-300 rounded-l-lg focus:outline-none focus:ring-2 focus:ring-purple-500"
              disabled={loading}
              aria-label="Your question"
            />
            <button
              type="submit"
              disabled={loading || !input.trim()}
              className="px-4 py-3 bg-purple-600 text-white rounded-r-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center"
              aria-label={loading ? "Sending..." : "Send message"}
            >
              {loading ? (
                <div className="flex items-center space-x-1">
                  <div className="w-1.5 h-1.5 bg-white rounded-full animate-pulse"></div>
                  <div
                    className="w-1.5 h-1.5 bg-white rounded-full animate-pulse"
                    style={{ animationDelay: "150ms" }}
                  ></div>
                  <div
                    className="w-1.5 h-1.5 bg-white rounded-full animate-pulse"
                    style={{ animationDelay: "300ms" }}
                  ></div>
                </div>
              ) : (
                <PaperAirplaneIcon className="h-5 w-5" />
              )}
            </button>
          </div>
        </form>
      </div>
    </div>
  );
};

export default Chat;
</file>

<file path="components/Navbar.tsx">
"use client";

import React, { useState, useEffect } from "react";
import Link from "next/link";
import { usePathname, useRouter } from "next/navigation";
import { createClient } from "@/lib/supabase/client";
import { Session } from "@supabase/supabase-js";

const Navbar = () => {
  const pathname = usePathname();
  const router = useRouter();
  const [session, setSession] = useState<Session | null>(null);
  const [loading, setLoading] = useState(true);
  const supabase = createClient();

  useEffect(() => {
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session);
      setLoading(false);
    });

    const {
      data: { subscription },
    } = supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session);
      setLoading(false);
    });

    return () => subscription?.unsubscribe();
  }, [supabase.auth]);

  const handleSignIn = async () => {
    setLoading(true);
    const { error } = await supabase.auth.signInWithOAuth({
      provider: "google",
      options: {
        redirectTo: `${window.location.origin}/auth/callback`,
      },
    });
    if (error) {
      console.error("Error signing in:", error.message);
      setLoading(false);
    }
  };

  const handleSignOut = async () => {
    setLoading(true);
    const { error } = await supabase.auth.signOut();
    if (error) {
      console.error("Error signing out:", error.message);
    } else {
      setSession(null);
      router.push("/");
    }
    setLoading(false);
  };

  return (
    <nav className="flex items-center justify-between w-full max-w-7xl mx-auto px-4 py-6">
      <Link href="/" className="flex items-center">
        <div className="w-10 h-10 bg-purple-600 rounded-full flex items-center justify-center mr-2">
          <svg
            xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 24 24"
            fill="white"
            className="w-6 h-6"
          >
            <path d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z" />
            <path d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z" />
          </svg>
        </div>
        <span className="text-2xl font-bold text-purple-600">PodAI</span>
      </Link>
      <div className="flex items-center space-x-4">
        {loading ? (
          <div className="text-gray-500">Loading...</div>
        ) : session ? (
          <>
            {pathname === "/dashboard" ? (
              <Link
                href="/"
                className="text-gray-600 hover:text-purple-600 transition-colors"
              >
                Home
              </Link>
            ) : (
              <Link
                href="/dashboard"
                className="text-gray-600 hover:text-purple-600 transition-colors"
              >
                Dashboard
              </Link>
            )}
            <Link
              href="/validate-transcript"
              className="text-gray-600 hover:text-purple-600 transition-colors"
            >
              Validate Transcript
            </Link>
            <span className="text-sm text-gray-600 hidden sm:inline">
              {session.user.email}
            </span>
            <button
              onClick={handleSignOut}
              className="px-4 py-2 border border-purple-600 text-purple-600 rounded-lg hover:bg-purple-50 transition-colors"
            >
              Sign Out
            </button>
          </>
        ) : (
          <>
            <Link
              href="/validate-transcript"
              className="text-gray-600 hover:text-purple-600 transition-colors mr-4"
            >
              Validate Transcript
            </Link>
            <button
              onClick={handleSignIn}
              className="px-4 py-2 bg-purple-600 text-white rounded-lg hover:bg-purple-700 transition-colors flex items-center space-x-2"
            >
              <span>Sign In with Google</span>
            </button>
          </>
        )}
      </div>
    </nav>
  );
};

export default Navbar;
</file>

<file path="components/Summary.tsx">
import React, { useEffect, useState } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import { toast } from "react-hot-toast";
import { DocumentDuplicateIcon } from "@heroicons/react/24/outline";
import { PodcastMetadata } from "./PodcastMetadata";

interface SummaryProps {
  summary: string;
  videoUrl: string;
}

const Summary: React.FC<SummaryProps> = ({ summary, videoUrl }) => {
  const [metadata, setMetadata] = useState<PodcastMetadata | null>(null);
  const [loading, setLoading] = useState(true);

  // Fetch metadata if it's not already in the summary
  useEffect(() => {
    const fetchMetadata = async () => {
      if (!videoUrl) return;

      try {
        setLoading(true);
        const response = await fetch("/api/podcast-metadata", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ url: videoUrl }),
        });

        if (response.ok) {
          const data = await response.json();
          setMetadata(data.metadata);
        }
      } catch (error) {
        console.error("Error fetching metadata:", error);
      } finally {
        setLoading(false);
      }
    };

    fetchMetadata();
  }, [videoUrl]);

  const handleCopy = async () => {
    try {
      // Include metadata in the copied content if available
      let fullContent = "";

      if (metadata) {
        fullContent += `# ${metadata.title}\n`;
        fullContent += `Channel: ${metadata.channelName}\n`;
        fullContent += `Duration: ${metadata.duration}\n`;

        // Add published date if available
        if (metadata.publishedAt) {
          const date = new Date(metadata.publishedAt);
          fullContent += `Published: ${date.toLocaleDateString()}\n`;
        }

        // Add view count if available
        if (metadata.viewCount) {
          fullContent += `Views: ${parseInt(
            metadata.viewCount
          ).toLocaleString()}\n`;
        }

        // Add like count if available
        if (metadata.likeCount) {
          fullContent += `Likes: ${parseInt(
            metadata.likeCount
          ).toLocaleString()}\n`;
        }

        fullContent += "\n";
      }

      fullContent += summary;

      await navigator.clipboard.writeText(fullContent);
      toast.success("Summary copied to clipboard!");
    } catch (error) {
      console.error("Failed to copy:", error);
      toast.error("Failed to copy to clipboard. Please try again.");
    }
  };

  return (
    <div className="bg-white rounded-lg">
      <div className="flex justify-end p-2">
        <button
          onClick={handleCopy}
          className="flex items-center px-3 py-1.5 text-sm bg-gray-100 text-gray-700 rounded-lg hover:bg-gray-200 transition-colors"
          aria-label="Copy summary to clipboard"
        >
          <DocumentDuplicateIcon className="h-4 w-4 mr-1.5" />
          Copy
        </button>
      </div>

      <div className="px-4 pb-4 overflow-y-auto max-h-[70vh]">
        {/* Metadata section has been removed */}

        <div className="w-full max-w-full overflow-hidden markdown-content bg-gray-50 border border-gray-200 rounded-lg p-6 py-0">
          <div className="prose prose-lg !max-w-full !w-full prose-headings:text-purple-700 prose-h1:text-2xl prose-h2:text-xl prose-h2:mt-8 prose-h2:mb-4 prose-h2:pb-2 prose-h2:border-b prose-h2:border-gray-200 prose-h3:text-lg prose-h3:text-gray-700 prose-h3:mt-6 prose-p:text-gray-600 prose-p:my-4 prose-p:leading-relaxed prose-ul:my-4 prose-ol:my-4 prose-li:my-1.5 prose-li:text-gray-600 prose-strong:text-purple-800 prose-strong:font-medium prose-a:text-purple-600 prose-a:no-underline hover:prose-a:underline">
            <ReactMarkdown remarkPlugins={[remarkGfm]}>{summary}</ReactMarkdown>
          </div>
        </div>
      </div>
    </div>
  );
};

export default Summary;
</file>

<file path="DEPLOYMENT_VERCEL.md">
# Deploying YouTube AI Podcast Assistant to Vercel

This document outlines the steps to deploy the application to Vercel.

## 1. Prerequisites

- Ensure your code is pushed to a Git repository (GitHub, GitLab, or Bitbucket).
- Have a Vercel account ([https://vercel.com/signup](https://vercel.com/signup)).

## 2. Vercel Project Setup

1.  Log in to your Vercel dashboard.
2.  Click **Add New...** -> **Project**.
3.  **Import Git Repository**: Select the Git provider where your repository is hosted and import the `youtube-ai-podcast-assistant` repository.
4.  Vercel should automatically detect it as a Next.js project.

## 3. Configure Project Settings

1.  **Framework Preset**: Verify Vercel sets it to "Next.js".
2.  **Build & Development Settings**: The defaults usually work for Next.js (`npm run build`, output directory `.next`). No changes are typically needed.
3.  **Environment Variables**: This is crucial.
    - Navigate to your project's **Settings** -> **Environment Variables**.
    - Add the following variables:
      - `OPENAI_API_KEY`: Enter your OpenAI API key. Mark it as **Secret**.
      - `NEXT_PUBLIC_SUPABASE_URL`: Enter your Supabase project URL.
      - `NEXT_PUBLIC_SUPABASE_ANON_KEY`: Enter your Supabase Anon Key.
      - `YOUTUBE_API_KEY`: Enter your YouTube Data API key. Mark it as **Secret**.
    - _Note: The `NEXT_PUBLIC_` prefixes are required for the Supabase variables to be accessible in the browser.\_

## 4. Deploy

1.  Review the settings.
2.  Click the **Deploy** button.
3.  Vercel will clone the repository, install dependencies (`npm install`), build the project (`npm run build`), and deploy it. Wait for the process to complete.

## 5. Update Supabase & Google Cloud Redirect URIs

_This is a critical post-deployment step._

1.  **Get Deployment URL**: Once Vercel deployment is successful, note your production URL (e.g., `your-project-name.vercel.app`).
2.  **Update Supabase**:
    - Go to your Supabase project dashboard -> **Authentication** -> **URL Configuration**.
    - In the **Redirect URLs** section, add your Vercel production URL followed by `/auth/v1/callback`.
    - Example: `https://your-project-name.vercel.app/auth/v1/callback`
    - Save the changes.
3.  **Update Google Cloud Console**:
    - Go to your Google Cloud project -> **APIs & Services** -> **Credentials**.
    - Find the OAuth 2.0 Client ID you configured for Supabase authentication.
    - Edit the client ID.
    - Under **Authorized redirect URIs**, add the _exact same_ Vercel callback URL as added in Supabase.
    - Example: `https://your-project-name.vercel.app/auth/v1/callback`
    - Save the changes.

_Failure to update these redirect URIs will prevent the Google Sign-In from working on your deployed Vercel application._

## 6. Testing

1.  Access your Vercel deployment URL in a browser.
2.  Verify the landing page loads correctly.
3.  Test the **Sign In** button and complete the Google OAuth flow. You should be redirected to the `/dashboard`.
4.  On the dashboard, enter a valid YouTube podcast URL.
5.  Click **Process Podcast**.
6.  Verify that the metadata, summary, and chat features work as expected.
7.  Test the **Sign Out** functionality.
</file>

<file path="README.md">
# YouTube AI Podcast Assistant

A modern web application that helps users extract insights from YouTube podcasts through AI-powered summarization and interactive chat.

## Features

- **User Authentication**: Secure sign-in via Google OAuth powered by Supabase
- **Podcast Transcription**: Automatically extracts transcripts from YouTube videos
- **YouTube Metadata Extraction**: Fetches video title, channel name, and duration for better context
- **AI-Powered Summarization**: Generates structured summaries of podcast content with:
  - Executive Summary
  - Key Insights with timestamps
  - Detailed Timeline
  - Notable Quotes
  - Related Resources
  - Thought-provoking Questions
- **Interactive Chat**: Ask specific questions about the podcast content and get AI-generated answers
- **Seamless Experience**: Enter a YouTube URL once and switch between summary and chat features
- **Markdown Support**: All AI-generated content is formatted in Markdown for better readability
- **Responsive Design**: Works well on both desktop and mobile devices
- **Error Handling**: Robust error handling for transcript extraction and API responses
- **Landing Page**: Modern landing page for unauthenticated users with sign-in options
- **Protected Dashboard**: Authenticated user workspace with podcast processing tools accessible only after login

## Tech Stack

- **Frontend**: Next.js 14, React, TypeScript, Tailwind CSS
- **Authentication**: Supabase (Auth, Google Provider)
- **UI Components**: React Markdown, Headless UI, Hero Icons, `@supabase/ssr`, `@supabase/supabase-js`
- **Notifications**: React Hot Toast
- **AI Integration**: OpenAI API (using GPT-4o-mini)
- **YouTube Integration**: YouTube Transcript API, YouTube oEmbed API
- **State Management**: React useState/useEffect hooks
- **Build Tools**: TypeScript, PostCSS, Autoprefixer
- **Routing**: App Router with middleware for authenticated/unauthenticated routes

## Getting Started

### Prerequisites

- Node.js 18+ and npm
- OpenAI API key
- Supabase Project: Set up a project on [Supabase](https://supabase.com/)
- Supabase Project URL and Anon Key
- Google Cloud Project: Configured with OAuth 2.0 credentials (Client ID & Secret)
- Authorized Redirect URI in Google Cloud matching your Supabase callback URL (e.g., `YOUR_SUPABASE_URL/auth/v1/callback`)
- Supabase Authentication configured with your Google Client ID and Secret

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/youtube-ai-podcast-assistant.git
   cd youtube-ai-podcast-assistant
   ```

2. Install dependencies:

   ```bash
   npm install
   npm install @supabase/ssr @supabase/supabase-js
   ```

3. Create a `.env.local` file in the root directory with your keys:

   ```dotenv
   OPENAI_API_KEY=your_openai_api_key_here
   NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
   ```

4. Start the development server:

   ```bash
   npm run dev
   ```

5. Open [http://localhost:3000](http://localhost:3000) in your browser to see the application.

## User Experience

### Non-authenticated Users

Non-authenticated users will see the landing page at the root URL (`/`) with:

- Navigation bar with "Sign In" button
- Engaging hero section with a visual representation of the chat interface and a "Get Started" button
- Feature highlights showcasing key capabilities
- Step-by-step guide on how the platform works
- Call-to-action buttons ("Get Started", "Sign In") triggering the Google OAuth flow via Supabase

### Authenticated Users

After signing in (via Google OAuth redirect handled by Supabase), users are directed to the protected dashboard (`/dashboard`) where they can:

1. See their email in the Navbar and a "Sign Out" button
2. Enter a YouTube podcast URL in the input field
3. Click "Process Podcast" to extract the content
4. View the AI-generated summary in the Summary tab, including video metadata
5. Switch to the Chat tab to ask specific questions about the podcast content

## How It Works

1. **Authentication (Optional for Landing Page, Required for Dashboard)**:
   - User clicks "Sign In" or "Get Started" on the landing page.
   - App initiates Supabase Google OAuth flow.
   - Supabase handles the redirect to Google and the callback (`/auth/callback`).
   - Session is established via cookies managed by `@supabase/ssr`.
   - Middleware (`middleware.ts`) protects `/dashboard` and redirects users based on auth state.
2. **User Input**: Authenticated user enters a YouTube podcast URL in the dashboard input field
3. **Metadata & Transcript Extraction**:
   - App extracts metadata (title, channel, duration) using YouTube oEmbed API
   - App extracts the transcript from the video using the YouTube Transcript API
4. **AI Processing**:
   - For summaries: Transcript and metadata are sent to OpenAI API with specific prompts
   - For chat: User questions are sent with the transcript context to get relevant answers
5. **Display**: Results are displayed in a clean, user-friendly interface with proper Markdown formatting

## Technical Highlights

- Supabase integration for secure Google OAuth authentication
- Server-side session management using Next.js Middleware and `@supabase/ssr` helpers
- Client-side authentication state handling in components (`Navbar`, `app/page.tsx`)
- Handles large transcripts by truncating them to fit within OpenAI token limits
- Custom prompts to generate well-structured summaries with specific sections
- Metadata enrichment for improved context in AI processing
- Chat history management for contextual conversation
- Accessibility features including proper ARIA labels
- Responsive UI with loading indicators for better user experience
- Error handling for various failure scenarios (invalid URLs, missing transcripts, API failures)

## Project Structure

```
youtube-ai-podcast-assistant/
├── app/                  # Next.js app directory
│   ├── api/              # API routes
│   │   ├── chat/         # Chat API endpoint
│   │   ├── podcast-metadata/ # Metadata API endpoint
│   │   └── summarize/    # Summarization API endpoint
│   ├── auth/             # Authentication related routes
│   │   ├── callback/     # Supabase OAuth callback handler
│   │   │   └── route.ts
│   │   └── auth-code-error/ # Error page for auth failures
│   │       └── page.tsx
│   ├── dashboard/        # Protected dashboard page (authenticated users)
│   │   └── page.tsx      # Dashboard component
│   ├── globals.css       # Global styles
│   ├── layout.tsx        # Root layout
│   └── page.tsx          # Landing page component (unauthenticated users)
├── components/           # React components
│   ├── Chat.tsx          # Chat interface component
│   ├── Summary.tsx       # Summary display component
│   ├── PodcastHeader.tsx # Podcast header component
│   ├── PodcastMetadata.tsx # Metadata provider component
│   ├── Navbar.tsx        # Navigation bar (used in Dashboard, shows auth state)
│   └── ErrorBoundary.tsx # Error handling component
├── lib/
│   └── supabase/         # Supabase client utilities
│       ├── client.ts     # Browser client
│       └── server.ts     # Server/Middleware client
├── public/               # Static assets
│   ├── app-screenshot-new.png    # Updated screenshot name
│   └── create-screenshot.html # Tool for generating app screenshots
├── .env.local            # Environment variables (API keys, Supabase URL/Key)
├── middleware.ts         # Next.js middleware for auth redirects & session refresh
├── next.config.js        # Next.js configuration
├── package.json          # Project dependencies
├── postcss.config.js     # PostCSS configuration
├── supabaseplan.md       # Supabase implementation plan (optional)
├── tailwind.config.js    # Tailwind CSS configuration
└── tsconfig.json         # TypeScript configuration
```

## Landing Page Features

The landing page includes:

- Navigation bar with "Sign In" button
- Hero section with two-column layout (text and app screenshot)
- Feature cards highlighting key capabilities
- "How It Works" section explaining the user flow
- Call-to-action section for conversion
- Responsive design that works well on all devices

## Dashboard Features

The dashboard includes:

- YouTube URL input form
- Tabbed interface for Summary and Chat views
- Podcast metadata display with video thumbnail
- Interactive chat interface
- AI-generated summary with structured sections
- Responsive layout for different screen sizes

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- OpenAI for providing the AI capabilities
- Next.js team for the amazing framework
- All open-source libraries used in this project
</file>

<file path="tailwind.config.js">
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./components/**/*.{js,ts,jsx,tsx,mdx}",
    "./app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
    extend: {
      backgroundImage: {
        "gradient-radial": "radial-gradient(var(--tw-gradient-stops))",
        "gradient-conic":
          "conic-gradient(from 180deg at 50% 50%, var(--tw-gradient-stops))",
      },
    },
  },
  plugins: [require("@tailwindcss/aspect-ratio")],
};
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": false,
    "noEmit": true,
    "incremental": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "plugins": [
      {
        "name": "next"
      }
    ],
    "baseUrl": ".",
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", ".next/types/**/*.ts", "**/*.ts", "**/*.tsx"],
  "exclude": ["node_modules"]
}
</file>

<file path="package.json">
{
  "name": "youtube-ai-transcriber",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@headlessui/react": "^1.7.18",
    "@heroicons/react": "^2.1.1",
    "@supabase/ssr": "^0.6.1",
    "@supabase/supabase-js": "^2.49.4",
    "@tailwindcss/aspect-ratio": "^0.4.2",
    "axios": "^1.6.7",
    "next": "14.2.26",
    "next-auth": "^4.24.5",
    "node-fetch": "^2.7.0",
    "openai": "^4.28.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-hot-toast": "^2.4.1",
    "react-markdown": "^10.0.0",
    "remark-gfm": "^4.0.1",
    "youtube-transcript": "^1.0.6"
  },
  "devDependencies": {
    "@types/node": "^20.11.19",
    "@types/node-fetch": "^2.6.12",
    "@types/react": "^18.2.57",
    "@types/react-dom": "^18.2.19",
    "autoprefixer": "^10.4.17",
    "eslint": "^8.56.0",
    "eslint-config-next": "14.1.0",
    "postcss": "^8.4.35",
    "tailwindcss": "^3.4.1",
    "typescript": "^5.3.3"
  }
}
</file>

<file path="app/api/chat/route.ts">
import { NextResponse } from "next/server";
import { YoutubeTranscript } from "youtube-transcript";
import OpenAI from "openai";

// Check if OpenAI API key is set
if (!process.env.OPENAI_API_KEY) {
  console.error("OPENAI_API_KEY is not set in environment variables");
  throw new Error("OPENAI_API_KEY is not set in environment variables");
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Custom function to fetch YouTube transcript directly
// This serves as a fallback if the youtube-transcript library fails
async function fetchYouTubeTranscriptDirectly(videoId: string) {
  try {
    console.log(`[${videoId}] Attempting direct transcript fetch for chat...`);

    // First, fetch the video page to extract necessary tokens
    const videoPageResponse = await fetch(
      `https://www.youtube.com/watch?v=${videoId}`,
      {
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
          "Accept-Language": "en-US,en;q=0.9",
          Accept:
            "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        },
      }
    );

    if (!videoPageResponse.ok) {
      throw new Error(
        `Failed to fetch video page: ${videoPageResponse.status}`
      );
    }

    const videoPageContent = await videoPageResponse.text();

    // Extract captions data from the page
    const captionsMatch = videoPageContent.match(
      /"captions":(.*?),"videoDetails"/
    );
    if (!captionsMatch || !captionsMatch[1]) {
      throw new Error("No captions data found in video page");
    }

    // Parse captions data
    let captionsData;
    try {
      // Clean up the JSON string before parsing
      const cleanedJson = captionsMatch[1]
        .replace(/\\"/g, '"')
        .replace(/\\\\/g, "\\");
      captionsData = JSON.parse(cleanedJson);
    } catch (e: any) {
      throw new Error(`Failed to parse captions data: ${e.message}`);
    }

    // Check if captions are available
    if (!captionsData.playerCaptionsTracklistRenderer) {
      throw new Error("Transcript is disabled on this video");
    }

    if (!captionsData.playerCaptionsTracklistRenderer.captionTracks) {
      throw new Error("No transcript tracks available");
    }

    // Get the first available transcript URL (usually English if available)
    const transcriptUrl =
      captionsData.playerCaptionsTracklistRenderer.captionTracks[0].baseUrl;

    // Fetch the transcript XML
    const transcriptResponse = await fetch(transcriptUrl, {
      headers: {
        "User-Agent":
          "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
      },
    });

    if (!transcriptResponse.ok) {
      throw new Error(
        `Failed to fetch transcript data: ${transcriptResponse.status}`
      );
    }

    const transcriptXml = await transcriptResponse.text();

    // Parse the XML to extract transcript
    const regex = /<text start="([^"]*)" dur="([^"]*)">([^<]*)<\/text>/g;
    let matches = [];
    let match;
    while ((match = regex.exec(transcriptXml)) !== null) {
      matches.push(match);
    }

    if (matches.length === 0) {
      throw new Error("Failed to parse transcript XML");
    }

    // Convert to transcript format
    const transcript = matches.map((match) => ({
      text: match[3]
        .replace(/&amp;/g, "&")
        .replace(/&lt;/g, "<")
        .replace(/&gt;/g, ">")
        .replace(/&#39;/g, "'")
        .replace(/&quot;/g, '"'),
      duration: parseFloat(match[2]),
      offset: parseFloat(match[1]),
    }));

    console.log(
      `[${videoId}] Successfully fetched transcript directly for chat: ${transcript.length} segments`
    );
    return transcript;
  } catch (error) {
    console.error(
      `[${videoId}] Direct transcript fetch for chat failed:`,
      error
    );
    throw error;
  }
}

export async function POST(request: Request) {
  try {
    // Parse request body
    const body = await request.json();
    const { url, question, chatHistory = [] } = body;

    console.log("Processing chat for URL:", url);
    console.log("Question:", question);

    if (!url) {
      console.error("No URL provided");
      return NextResponse.json({ error: "No URL provided" }, { status: 400 });
    }

    if (!question) {
      console.error("No question provided");
      return NextResponse.json(
        { error: "No question provided" },
        { status: 400 }
      );
    }

    // Extract video ID from URL
    const videoId = url.match(
      /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
    )?.[1];

    if (!videoId) {
      console.error("Invalid YouTube URL:", url);
      return NextResponse.json(
        { error: "Invalid YouTube URL" },
        { status: 400 }
      );
    }

    console.log("Extracted video ID:", videoId);

    // Get transcript
    try {
      console.log(`[${videoId}] Attempting to fetch transcript for chat...`);

      let transcript;

      // First try with the standard library
      try {
        transcript = await YoutubeTranscript.fetchTranscript(videoId);
        console.log(
          `[${videoId}] Standard library successfully fetched transcript for chat: ${transcript?.length} segments`
        );
      } catch (standardError) {
        console.error(
          `[${videoId}] Standard library transcript fetch failed for chat:`,
          standardError
        );
        console.log(
          `[${videoId}] Attempting fallback transcript fetch method for chat...`
        );

        // Try with our custom direct fetch method
        transcript = await fetchYouTubeTranscriptDirectly(videoId);
      }

      console.log(
        `[${videoId}] Raw transcript response received for chat. Length: ${transcript?.length}`
      );

      if (!transcript || transcript.length === 0) {
        console.error(
          `[${videoId}] No transcript data found in the response for chat.`
        );
        return NextResponse.json(
          { error: "No transcript found for this video" },
          { status: 404 }
        );
      }

      const transcriptText = transcript.map((item) => item.text).join(" ");
      console.log(
        `[${videoId}] Transcript processed for chat. Text length: ${transcriptText.length}`
      );

      if (!transcriptText || transcriptText.trim() === "") {
        console.error(
          `[${videoId}] Processed transcript text is empty for chat.`
        );
        return NextResponse.json(
          { error: "Empty transcript found for this video" },
          { status: 404 }
        );
      }

      // Truncate transcript if it's too long (OpenAI has token limits)
      const maxChars = 42000; // Approximately 12000 tokens
      const truncatedText =
        transcriptText.length > maxChars
          ? transcriptText.slice(0, maxChars) + "..."
          : transcriptText;

      console.log(
        `[${videoId}] Truncated transcript text length for chat: ${truncatedText.length}`
      );

      // Prepare chat history for the API
      const messages = [
        {
          role: "system",
          content: `You're a friendly podcast assistant who helps users understand podcast content better. You have access to the transcript of a YouTube podcast. Answer questions about the podcast in a conversational, helpful way. 

When answering:
- Be specific and reference the content directly
- If you can identify timestamps for relevant parts, include them
- If the question asks about something not covered in the podcast, politely explain that it wasn't discussed
- Keep your tone casual and friendly, like you're chatting with a friend
- If appropriate, mention related topics that were discussed in the podcast that might interest the user

Here's the podcast transcript: ${truncatedText}`,
        },
        ...chatHistory,
        {
          role: "user",
          content: question,
        },
      ];

      // Generate answer using OpenAI
      try {
        console.log("Calling OpenAI API for chat...");
        const completion = await openai.chat.completions.create({
          messages,
          model: "gpt-4o-mini",
          max_tokens: 1024,
          temperature: 0.7,
        });

        console.log("OpenAI API response received");
        const answer = completion.choices[0].message.content;

        if (!answer) {
          console.error("No answer generated by OpenAI");
          throw new Error("No answer generated by OpenAI");
        }

        console.log("Answer length:", answer.length, "characters");
        return NextResponse.json({
          answer,
          chatHistory: [
            ...chatHistory,
            { role: "user", content: question },
            { role: "assistant", content: answer },
          ],
        });
      } catch (openaiError: any) {
        console.error("OpenAI API Error:", {
          message: openaiError.message,
          type: openaiError.type,
          stack: openaiError.stack,
          response: openaiError.response?.data,
        });
        return NextResponse.json(
          {
            error: `Failed to generate answer using AI: ${openaiError.message}`,
          },
          { status: 500 }
        );
      }
    } catch (transcriptError: any) {
      console.error(`[${videoId}] Transcript Fetching Error (Chat):`, {
        message: transcriptError.message,
        name: transcriptError.name,
        // Consider logging more properties if available, e.g., error code
        stack: transcriptError.stack,
      });
      return NextResponse.json(
        {
          error: `Failed to fetch video transcript: ${transcriptError.message}`,
        },
        { status: 404 }
      );
    }
  } catch (error: any) {
    console.error("General Error:", {
      message: error.message,
      stack: error.stack,
    });
    return NextResponse.json(
      { error: `Failed to process request: ${error.message}` },
      { status: 500 }
    );
  }
}
</file>

<file path="TRANSCRIPT_ISSUE_PLAN.md">
# YouTube Transcript Issue Troubleshooting Plan

This document outlines our systematic approach to resolving the YouTube transcript fetching issue that occurs on the Vercel deployment but not in local development.

## Current Issue

- ✅ Application works correctly in local development environment
- ❌ Application fails on Vercel deployment with multiple errors:
  - `Failed to fetch video transcript: [YoutubeTranscript] 🚨 Transcript is disabled on this video`
  - `Failed to fetch metadata: Unauthorized`
  - `No captions data found in video page`

## Hypotheses

1. **CORS Restrictions**: Vercel's environment may have stricter CORS policies than local development
2. **YouTube IP Blocking**: YouTube may be blocking or restricting requests from Vercel's server IP ranges
3. **Library Compatibility**: The transcript fetching library might not be compatible with Vercel's serverless environment
4. **Authentication/Headers**: The requests from Vercel might be missing necessary headers or user-agent information
5. **Server vs. Client Execution**: The code might be executing in a different context (client vs server) on Vercel
6. **YouTube Page Structure**: The structure of YouTube pages might be different when accessed from Vercel's IP ranges
7. **API Key Issues**: The YouTube API key might not be properly configured in Vercel or might have restrictions
8. **Page Format Changes**: YouTube might be serving different HTML formats for different client types

## Current Diagnosis

Initial diagnosis indicated that the YouTube API key was missing from the Vercel environment. This was added, but the issue persisted. Further investigation revealed several key issues:

1. The URL construction for internal API calls was missing the proper protocol prefix on Vercel deployments
2. YouTube transcript fetching may be blocked by YouTube when coming from Vercel IP addresses
3. YouTube returns different page structures when accessed from cloud providers vs. residential IPs
4. The regex pattern used to extract captions data was failing on certain videos
5. The podcast metadata API was failing with an "Unauthorized" error, likely due to YouTube API key issues or restrictions

## Implemented Solution

We've addressed these issues with a multi-faceted approach:

1. Added more detailed logging to track down the exact point of failure
2. Fixed the URL construction for internal API calls to include the proper protocol
3. Implemented a custom fallback method for transcript fetching that uses a direct approach with browser-like headers
4. Added retry logic to try multiple methods of fetching transcripts
5. Implemented multiple regex patterns to extract captions from different YouTube page structures
6. Added timeout handling for HTTP requests to prevent hanging in error cases
7. Improved error handling and user-facing error messages
8. Added direct fallbacks for podcast metadata using oEmbed instead of the YouTube API
9. Implemented YouTube's Innertube API approach for transcript fetching as a new fallback method
10. Provided more robust error handling to present useful information to the user even when transcripts can't be fetched

### Phase 1: Initial Diagnosis & Fixes

✅ Identified missing API keys and URL construction issues

### Phase 2: First Iteration of Solutions

✅ Improved the server-side transcript fetching code with a robust fallback solution
✅ Added proper error handling with specific error types
✅ Added browser-like headers to all requests

### Phase 3: Enhanced Approach (Latest)

✅ **3.1 Multiple Approach Strategy**

- Implemented 4 different methods to get transcripts: standard library, direct fetch, YouTube API, and Innertube API
- Added cascading fallbacks to try all methods before failing
- Improved regex patterns for all extraction methods

✅ **3.2 API Key & Authentication**

- Added fallbacks for when the YouTube API key is missing or restricted
- Implemented direct oEmbed approach for metadata that doesn't require API key

✅ **3.3 Enhanced Error Handling**

- Improved error classification and user-friendly messages
- Return metadata even when transcript fetching fails
- Added specific handling for different error types

✅ **3.4 YouTube Innertube API**

- Implemented YouTube's internal API approach for transcript fetching
- Added multiple patterns for extracting necessary tokens from the page
- Included fallbacks at every level of the process

## Monitoring and Validation

For the implemented solution:

1. Deploy to Vercel
2. Test with at least 3 different YouTube videos:
   - One with known captions
   - One with auto-generated captions
   - One in a non-English language
3. Monitor logs for any errors
4. Test with the specific video ID that previously failed: b9gPwO-IsB4
5. Check if metadata is returned even when transcript fetching fails

## Success Criteria

- Application successfully retrieves transcripts for videos that have them available
- Application properly handles and communicates when transcripts are unavailable
- Solution works consistently across multiple videos and over time
- User receives helpful error messages when transcripts cannot be fetched
- Basic functionality continues to work even when some components fail (graceful degradation)

## Future Enhancements (If Needed)

- [ ] **YouTube Data API for Captions**

  - Explore the use of the official YouTube Data API to fetch captions (requires OAuth)
  - This would be more reliable but more complex to implement

- [ ] **Alternative Libraries**

  - Research and test alternative YouTube transcript libraries
  - Evaluate newer libraries that might handle server-side environments better

- [ ] **Proxy Solution**
  - Create a proxy API endpoint that forwards requests to YouTube from a non-Vercel IP
  - Consider using a serverless function on a different provider or a dedicated server

## Implementation Notes

Each attempted solution has significantly improved our resilience and error handling. Our current approach tries multiple methods before failing, provides clear error messages, and gracefully degrades by providing metadata even when transcripts can't be fetched.

## Rollback Plan

If any implementation significantly degrades the application:

- Revert to the previous working deployment
- Document what caused the issue for future reference
</file>

<file path="app/api/summarize/route.ts">
import { NextResponse } from "next/server";
import { YoutubeTranscript } from "youtube-transcript";
import OpenAI from "openai";

// Check if OpenAI API key is set
if (!process.env.OPENAI_API_KEY) {
  console.error("OPENAI_API_KEY is not set in environment variables");
  throw new Error("OPENAI_API_KEY is not set in environment variables");
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Custom function to fetch YouTube transcript directly
// This serves as a fallback if the youtube-transcript library fails
async function fetchYouTubeTranscriptDirectly(videoId: string) {
  try {
    console.log(`[${videoId}] Attempting direct transcript fetch...`);

    // First, fetch the video page to extract necessary tokens
    const videoPageResponse = await fetch(
      `https://www.youtube.com/watch?v=${videoId}`,
      {
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
          "Accept-Language": "en-US,en;q=0.9",
          Accept:
            "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        },
        // Add timeout to prevent hanging requests
        signal: AbortSignal.timeout(15000), // 15 second timeout
      }
    );

    if (!videoPageResponse.ok) {
      throw new Error(
        `Failed to fetch video page: ${videoPageResponse.status} ${videoPageResponse.statusText}`
      );
    }

    // Check content type to ensure we got HTML
    const contentType = videoPageResponse.headers.get("content-type");
    if (!contentType || !contentType.includes("text/html")) {
      throw new Error(`Invalid content type returned: ${contentType}`);
    }

    const videoPageContent = await videoPageResponse.text();

    // Check if we got a meaningful response
    if (!videoPageContent || videoPageContent.length < 1000) {
      throw new Error("Empty or too short response from YouTube");
    }

    // Extract captions data from the page
    const captionsMatch = videoPageContent.match(
      /"captions":(.*?),"videoDetails"/
    );

    // If the first pattern doesn't match, try alternative patterns
    let captionsData;
    let rawCaptionsData = null;

    if (captionsMatch && captionsMatch[1]) {
      rawCaptionsData = captionsMatch[1];
    } else {
      // Try alternative pattern
      const altCaptionsMatch = videoPageContent.match(
        /\\"captionTracks\\":(\[.*?\])/
      );

      if (altCaptionsMatch && altCaptionsMatch[1]) {
        // Directly create a structure compatible with our existing code
        console.log(`[${videoId}] Found captions using alternative pattern 1`);

        try {
          // Clean the JSON string before parsing
          const cleanedAltJson = altCaptionsMatch[1]
            .replace(/\\"/g, '"')
            .replace(/\\\\u/g, "\\u")
            .replace(/\\\\/g, "\\");

          const captionTracks = JSON.parse(cleanedAltJson);

          if (captionTracks && captionTracks.length > 0) {
            // Create a structure compatible with our existing code
            rawCaptionsData = JSON.stringify({
              playerCaptionsTracklistRenderer: {
                captionTracks: captionTracks,
              },
            });
          }
        } catch (parseError) {
          console.error(
            `[${videoId}] Failed to parse alternative captions data:`,
            parseError
          );
        }
      }

      // If still no match, try a third pattern that looks for direct baseUrl
      if (!rawCaptionsData) {
        const thirdPatternMatch = videoPageContent.match(
          /\\"baseUrl\\":\\"(https:\/\/www\.youtube\.com\/api\/timedtext[^"\\]*)/
        );

        if (thirdPatternMatch && thirdPatternMatch[1]) {
          console.log(
            `[${videoId}] Found captions using alternative pattern 2`
          );

          // Extract the URL and decode it
          const transcriptUrl = thirdPatternMatch[1]
            .replace(/\\u0026/g, "&")
            .replace(/\\\\/g, "\\");

          // Create a compatible structure with the URL directly
          rawCaptionsData = JSON.stringify({
            playerCaptionsTracklistRenderer: {
              captionTracks: [
                {
                  baseUrl: transcriptUrl,
                },
              ],
            },
          });
        }
      }
    }

    if (!rawCaptionsData) {
      throw new Error("No captions data found in video page");
    }

    // Parse captions data
    try {
      // Clean up the JSON string before parsing
      const cleanedJson = rawCaptionsData
        .replace(/\\"/g, '"')
        .replace(/\\\\/g, "\\");
      captionsData = JSON.parse(cleanedJson);
    } catch (e: any) {
      throw new Error(`Failed to parse captions data: ${e.message}`);
    }

    // Check if captions are available
    if (!captionsData.playerCaptionsTracklistRenderer) {
      throw new Error("Transcript is disabled on this video");
    }

    if (!captionsData.playerCaptionsTracklistRenderer.captionTracks) {
      throw new Error("No transcript tracks available");
    }

    // Get the first available transcript URL (usually English if available)
    const transcriptUrl =
      captionsData.playerCaptionsTracklistRenderer.captionTracks[0].baseUrl;

    // Fetch the transcript XML
    const transcriptResponse = await fetch(transcriptUrl, {
      headers: {
        "User-Agent":
          "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
      },
      // Add timeout to prevent hanging requests
      signal: AbortSignal.timeout(10000), // 10 second timeout
    });

    if (!transcriptResponse.ok) {
      throw new Error(
        `Failed to fetch transcript data: ${transcriptResponse.status} ${transcriptResponse.statusText}`
      );
    }

    const transcriptXml = await transcriptResponse.text();

    // Validate that we received proper XML data
    if (!transcriptXml || !transcriptXml.includes("<transcript>")) {
      throw new Error("Invalid transcript data received");
    }

    // Parse the XML to extract transcript
    const regex = /<text start="([^"]*)" dur="([^"]*)">([^<]*)<\/text>/g;
    let matches = [];
    let match;
    while ((match = regex.exec(transcriptXml)) !== null) {
      matches.push(match);
    }

    if (matches.length === 0) {
      throw new Error("Failed to parse transcript XML");
    }

    // Convert to transcript format
    const transcript = matches.map((match) => ({
      text: match[3]
        .replace(/&amp;/g, "&")
        .replace(/&lt;/g, "<")
        .replace(/&gt;/g, ">")
        .replace(/&#39;/g, "'")
        .replace(/&quot;/g, '"'),
      duration: parseFloat(match[2]),
      offset: parseFloat(match[1]),
    }));

    console.log(
      `[${videoId}] Successfully fetched transcript directly: ${transcript.length} segments`
    );
    return transcript;
  } catch (error) {
    console.error(`[${videoId}] Direct transcript fetch failed:`, error);
    throw error;
  }
}

// Helper function to fetch podcast metadata
const fetchPodcastMetadata = async (videoId: string) => {
  try {
    // We need to use a fully qualified URL in server components
    // Since we need to make an internal API call, construct the URL based on the request URL
    // This is a self-request to our own API endpoint
    const origin = process.env.VERCEL_URL
      ? `https://${process.env.VERCEL_URL}`
      : process.env.NODE_ENV === "development"
      ? "http://localhost:3000"
      : "";

    console.log("Using API origin:", origin);

    try {
      const response = await fetch(`${origin}/api/podcast-metadata`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          url: `https://www.youtube.com/watch?v=${videoId}`,
        }),
        // Add timeout to prevent hanging requests
        signal: AbortSignal.timeout(15000), // 15 second timeout
      });

      if (!response.ok) {
        throw new Error(`Failed to fetch metadata: ${response.statusText}`);
      }

      const data = await response.json();
      return data.metadata;
    } catch (fetchError) {
      console.error("Error making metadata request:", fetchError);

      // If the internal API call fails, try fetching directly from YouTube's oEmbed API
      // as a backup that doesn't require the YouTube API key
      console.log(
        `[${videoId}] Attempting direct oEmbed fallback for metadata...`
      );

      const oEmbedResponse = await fetch(
        `https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v=${videoId}&format=json`,
        {
          headers: {
            "User-Agent":
              "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
          },
          signal: AbortSignal.timeout(10000), // 10 second timeout
        }
      );

      if (!oEmbedResponse.ok) {
        throw new Error(`oEmbed fallback failed: ${oEmbedResponse.statusText}`);
      }

      const oEmbedData = await oEmbedResponse.json();

      // Create a simplified metadata object from oEmbed data
      return {
        title: oEmbedData.title || "YouTube Video",
        channelName: oEmbedData.author_name || "Unknown Channel",
        duration: "Unknown duration",
        videoId: videoId,
        description: "Fetched with fallback method",
      };
    }
  } catch (error) {
    console.error("Error fetching podcast metadata:", error);

    // Return minimal metadata using just the video ID since that's all we really need
    return {
      title: "YouTube Video",
      channelName: "Unknown Channel",
      duration: "Unknown duration",
      videoId: videoId,
      description: "Could not fetch metadata",
    };
  }
};

// Add a new function for fetching transcripts via the official YouTube API
async function fetchYouTubeTranscriptViaAPI(videoId: string) {
  try {
    console.log(
      `[${videoId}] Attempting to fetch transcript via YouTube API...`
    );

    const apiKey = process.env.YOUTUBE_API_KEY;

    if (!apiKey) {
      throw new Error("YouTube API key is not configured");
    }

    // First, we need to get the caption track IDs
    const captionListUrl = `https://www.googleapis.com/youtube/v3/captions?part=snippet&videoId=${videoId}&key=${apiKey}`;

    const captionListResponse = await fetch(captionListUrl, {
      headers: {
        Accept: "application/json",
      },
      signal: AbortSignal.timeout(15000), // 15 second timeout
    });

    if (!captionListResponse.ok) {
      throw new Error(
        `Failed to fetch caption list: ${captionListResponse.status} ${captionListResponse.statusText}`
      );
    }

    const captionList = await captionListResponse.json();

    if (!captionList.items || captionList.items.length === 0) {
      throw new Error("No caption tracks found");
    }

    // Find the English track preferably, or use the first one
    let captionTrack = captionList.items[0];
    for (const track of captionList.items) {
      if (track.snippet.language === "en") {
        captionTrack = track;
        break;
      }
    }

    // Now get the actual transcript using the YouTube transcript URL format
    const transcriptUrl = `https://www.youtube.com/api/timedtext?lang=${captionTrack.snippet.language}&v=${videoId}&fmt=srv3`;

    const transcriptResponse = await fetch(transcriptUrl, {
      headers: {
        "User-Agent":
          "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
      },
      signal: AbortSignal.timeout(10000), // 10 second timeout
    });

    if (!transcriptResponse.ok) {
      throw new Error(
        `Failed to fetch transcript data: ${transcriptResponse.status} ${transcriptResponse.statusText}`
      );
    }

    const transcriptXml = await transcriptResponse.text();

    // Parse the XML to extract transcript
    const regex = /<text start="([^"]*)" dur="([^"]*)">([^<]*)<\/text>/g;
    let matches = [];
    let match;
    while ((match = regex.exec(transcriptXml)) !== null) {
      matches.push(match);
    }

    if (matches.length === 0) {
      throw new Error("Failed to parse transcript XML");
    }

    // Convert to transcript format
    const transcript = matches.map((match) => ({
      text: match[3]
        .replace(/&amp;/g, "&")
        .replace(/&lt;/g, "<")
        .replace(/&gt;/g, ">")
        .replace(/&#39;/g, "'")
        .replace(/&quot;/g, '"'),
      duration: parseFloat(match[2]),
      offset: parseFloat(match[1]),
    }));

    console.log(
      `[${videoId}] Successfully fetched transcript via API: ${transcript.length} segments`
    );
    return transcript;
  } catch (error) {
    console.error(`[${videoId}] YouTube API transcript fetch failed:`, error);
    throw error;
  }
}

// Add a new function using a completely different scraping approach
async function fetchYouTubeTranscriptViaInnertubeAPI(videoId: string) {
  try {
    console.log(
      `[${videoId}] Attempting to fetch transcript via Innertube API...`
    );

    // First get the initial page to extract context data
    const initialResponse = await fetch(
      `https://www.youtube.com/watch?v=${videoId}`,
      {
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
          "Accept-Language": "en-US,en;q=0.9",
          Accept:
            "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        },
        signal: AbortSignal.timeout(15000), // 15 second timeout
      }
    );

    if (!initialResponse.ok) {
      throw new Error(
        `Failed to fetch video page: ${initialResponse.status} ${initialResponse.statusText}`
      );
    }

    const html = await initialResponse.text();

    // Extract API key - try multiple patterns
    let innertubeApiKey = null;

    // Pattern 1
    const apiKeyMatch = html.match(/"INNERTUBE_API_KEY":"([^"]+)"/);
    if (apiKeyMatch && apiKeyMatch[1]) {
      innertubeApiKey = apiKeyMatch[1];
    }

    // Pattern 2 (alternative)
    if (!innertubeApiKey) {
      const apiKeyMatch2 = html.match(/innertubeApiKey":"([^"]+)"/);
      if (apiKeyMatch2 && apiKeyMatch2[1]) {
        innertubeApiKey = apiKeyMatch2[1];
      }
    }

    // Pattern 3 (another alternative)
    if (!innertubeApiKey) {
      const apiKeyMatch3 = html.match(
        /INNERTUBE_API_KEY\s*[:=]\s*['"]([^'"]+)['"]/
      );
      if (apiKeyMatch3 && apiKeyMatch3[1]) {
        innertubeApiKey = apiKeyMatch3[1];
      }
    }

    if (!innertubeApiKey) {
      throw new Error("Could not extract Innertube API key");
    }

    // Extract client version - try multiple patterns
    let clientVersion = null;

    // Pattern a
    const clientVersionMatch = html.match(/"clientVersion":"([^"]+)"/);
    if (clientVersionMatch && clientVersionMatch[1]) {
      clientVersion = clientVersionMatch[1];
    }

    // Pattern b (alternative)
    if (!clientVersion) {
      const clientVersionMatch2 = html.match(/clientVersion":"([^"]+)"/);
      if (clientVersionMatch2 && clientVersionMatch2[1]) {
        clientVersion = clientVersionMatch2[1];
      }
    }

    // If all else fails, use a hardcoded recent version
    if (!clientVersion) {
      console.log(`[${videoId}] Using hardcoded client version as fallback`);
      clientVersion = "2.20240529.01.00";
    }

    // Try alternative direct method for getting transcripts if we have issues with the API
    try {
      // Now we'll use the Innertube API to request the transcript
      const response = await fetch(
        `https://www.youtube.com/youtubei/v1/get_transcript?key=${innertubeApiKey}`,
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "User-Agent":
              "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept-Language": "en-US,en;q=0.9",
          },
          body: JSON.stringify({
            context: {
              client: {
                clientName: "WEB",
                clientVersion: clientVersion,
                hl: "en",
                gl: "US",
              },
            },
            params: Buffer.from(JSON.stringify({ videoId })).toString("base64"),
          }),
          signal: AbortSignal.timeout(10000), // 10 second timeout
        }
      );

      if (!response.ok) {
        throw new Error(
          `Failed to fetch transcript: ${response.status} ${response.statusText}`
        );
      }

      const data = await response.json();

      // Check if there are captions
      if (
        !data ||
        !data.actions ||
        !data.actions[0] ||
        !data.actions[0].updateEngagementPanelAction
      ) {
        throw new Error("No transcript data in response");
      }

      const transcriptRenderer =
        data.actions[0].updateEngagementPanelAction.content.transcriptRenderer;

      if (
        !transcriptRenderer ||
        !transcriptRenderer.body ||
        !transcriptRenderer.body.transcriptBodyRenderer
      ) {
        throw new Error("No transcript body found");
      }

      const cueGroups =
        transcriptRenderer.body.transcriptBodyRenderer.cueGroups;

      if (!cueGroups || cueGroups.length === 0) {
        throw new Error("No cue groups found in transcript");
      }

      // Parse the transcript data
      const transcript = cueGroups.map((cueGroup) => {
        const cue =
          cueGroup.transcriptCueGroupRenderer.cues[0].transcriptCueRenderer;
        return {
          text: cue.cue.simpleText,
          duration: 0, // Transcript from this API might not include durations
          offset: parseFloat(cue.startOffsetMs) / 1000, // Convert ms to seconds
        };
      });

      console.log(
        `[${videoId}] Successfully fetched transcript via Innertube API: ${transcript.length} segments`
      );
      return transcript;
    } catch (innerApiError) {
      console.error(
        `[${videoId}] Innertube API request failed:`,
        innerApiError
      );

      // We might still be able to extract the transcript directly from the page
      console.log(
        `[${videoId}] Attempting to extract transcript directly from page...`
      );

      // Find the transcript data in the initial page response
      const transcriptData = html.match(/"captionTracks":\[(.*?)\]/);
      if (!transcriptData || !transcriptData[1]) {
        throw new Error("No transcript data found in page");
      }

      // Find the first caption track URL
      const baseUrlMatch = transcriptData[1].match(/"baseUrl":"([^"]+)"/);
      if (!baseUrlMatch || !baseUrlMatch[1]) {
        throw new Error("No baseUrl found in transcript data");
      }

      // Clean up the URL (unescape)
      const transcriptUrl = baseUrlMatch[1]
        .replace(/\\u0026/g, "&")
        .replace(/\\\//g, "/");

      // Fetch the transcript XML
      const transcriptResponse = await fetch(transcriptUrl, {
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        },
        signal: AbortSignal.timeout(10000), // 10 second timeout
      });

      if (!transcriptResponse.ok) {
        throw new Error(
          `Failed to fetch transcript data: ${transcriptResponse.status} ${transcriptResponse.statusText}`
        );
      }

      const transcriptXml = await transcriptResponse.text();

      // Parse the XML to extract transcript
      const regex = /<text start="([^"]*)" dur="([^"]*)">([^<]*)<\/text>/g;
      let matches = [];
      let match;
      while ((match = regex.exec(transcriptXml)) !== null) {
        matches.push(match);
      }

      if (matches.length === 0) {
        throw new Error("Failed to parse transcript XML");
      }

      // Convert to transcript format
      const transcript = matches.map((match) => ({
        text: match[3]
          .replace(/&amp;/g, "&")
          .replace(/&lt;/g, "<")
          .replace(/&gt;/g, ">")
          .replace(/&#39;/g, "'")
          .replace(/&quot;/g, '"'),
        duration: parseFloat(match[2]),
        offset: parseFloat(match[1]),
      }));

      console.log(
        `[${videoId}] Successfully extracted transcript from page: ${transcript.length} segments`
      );
      return transcript;
    }
  } catch (error) {
    console.error(`[${videoId}] Innertube API transcript fetch failed:`, error);
    throw error;
  }
}

export async function POST(request: Request) {
  try {
    // Parse request body
    const body = await request.json();
    const { url } = body;

    console.log("Processing URL:", url);

    if (!url) {
      console.error("No URL provided");
      return NextResponse.json({ error: "No URL provided" }, { status: 400 });
    }

    // Extract video ID from URL
    const videoId = url.match(
      /(?:youtu\.be\/|youtube\.com\/(?:watch\?v=|embed\/|v\/))([^&?\s]+)/
    )?.[1];

    if (!videoId) {
      console.error("Invalid YouTube URL:", url);
      return NextResponse.json(
        { error: "Invalid YouTube URL" },
        { status: 400 }
      );
    }

    console.log("Extracted video ID:", videoId);

    // Fetch podcast metadata
    const metadata = await fetchPodcastMetadata(videoId);
    console.log("Fetched metadata:", metadata);

    // Get transcript
    try {
      console.log(`[${videoId}] Attempting to fetch transcript...`);

      let transcript;

      // First try with the standard library
      try {
        transcript = await YoutubeTranscript.fetchTranscript(videoId);
        console.log(
          `[${videoId}] Standard library successfully fetched transcript: ${transcript?.length} segments`
        );
      } catch (standardError) {
        console.error(
          `[${videoId}] Standard library transcript fetch failed:`,
          standardError
        );
        console.log(
          `[${videoId}] Attempting fallback transcript fetch method...`
        );

        // Try with our custom direct fetch method
        try {
          transcript = await fetchYouTubeTranscriptDirectly(videoId);
        } catch (directError) {
          console.error(
            `[${videoId}] Direct transcript fetch failed:`,
            directError
          );

          // Try with our YouTube API method
          try {
            transcript = await fetchYouTubeTranscriptViaAPI(videoId);
          } catch (apiError) {
            console.error(
              `[${videoId}] YouTube API transcript fetch failed:`,
              apiError
            );

            // Try with our Innertube API method as last resort
            transcript = await fetchYouTubeTranscriptViaInnertubeAPI(videoId);
          }
        }
      }

      console.log(
        `[${videoId}] Raw transcript response received. Length: ${transcript?.length}`
      );

      if (!transcript || transcript.length === 0) {
        console.error(`[${videoId}] No transcript data found in the response.`);
        return NextResponse.json(
          { error: "No transcript found for this video" },
          { status: 404 }
        );
      }

      const transcriptText = transcript.map((item) => item.text).join(" ");
      console.log(
        `[${videoId}] Transcript processed. Text length: ${transcriptText.length}`
      );

      if (!transcriptText || transcriptText.trim() === "") {
        console.error(`[${videoId}] Processed transcript text is empty.`);
        return NextResponse.json(
          { error: "Empty transcript found for this video" },
          { status: 404 }
        );
      }

      // Truncate transcript if it's too long (OpenAI has token limits)
      const maxChars = 42000; // Approximately 12000 tokens
      const truncatedText =
        transcriptText.length > maxChars
          ? transcriptText.slice(0, maxChars) + "..."
          : transcriptText;

      console.log(
        `[${videoId}] Truncated transcript text length: ${truncatedText.length}`
      );

      // Generate summary using OpenAI
      try {
        console.log("Calling OpenAI API...");

        // Prepare metadata information for the prompt
        const metadataInfo = metadata
          ? `Video Title: ${metadata.title}\nChannel: ${metadata.channelName}\nDuration: ${metadata.duration}\n\n`
          : "";

        const completion = await openai.chat.completions.create({
          messages: [
            {
              role: "system",
              content: `You're a chill podcast buddy who loves breaking down episodes in a friendly, conversational way. Talk like you're texting a friend about a cool podcast you just heard. Keep it casual but insightful!

Output Format (in Markdown):
1. ## Executive Summary
   Give a quick overview of what the podcast was about - the main vibes and key points. Make it 2 paragraphs. Keep it conversational and engaging.

2. ## Key Insights
   Identify and explain the most important ideas, revelations, or arguments presented in the podcast. Generate 5-7 points. For each one:
   - Explain it in a casual, friendly way yet insightful
   - Why it's worth thinking about
   - Add a timestamp if you can find one

3. ## Detailed Timeline
   Create a chronological breakdown of the podcast with timestamps at meaningful transition points:
   - [00:00:00] - [00:XX:XX]: Brief description of opening segment
   - [00:XX:XX] - [00:XX:XX]: Brief description of next topic/segment
  (Continue throughout the entire podcast)

4. ## Notable Quotes
   The best lines that stood out. Generate 3-5 points. For each one:
   - "Direct quote" - Who said it (timestamp if you have it)

5. ## Related Stuff
   Any books, articles, people, or other cool things they mentioned that listeners might want to check out.

6. ## Questions to Think About
   Some interesting questions that came up that might make you think. Generate 5-7 points.

Guidelines:
- Skip the boring parts and focus on the good stuff
- Point out when topics change
- Keep your personal opinions out of it
- Highlight the surprising or unique perspectives
- Note when people agree or disagree
- Think about what this all means in the bigger picture`,
            },
            {
              role: "user",
              content: `Please analyze the following podcast transcript and provide a summary according to the specified format:

${metadataInfo}${truncatedText}`,
            },
          ],
          model: "gpt-4o-mini",
          max_tokens: 2048,
          temperature: 0.7,
        });

        console.log("OpenAI API response received");
        const summary = completion.choices[0].message.content;

        if (!summary) {
          console.error("No summary generated by OpenAI");
          throw new Error("No summary generated by OpenAI");
        }

        // Format the summary to ensure proper Markdown
        const formattedSummary = summary
          // Ensure proper line breaks for headers
          .replace(/^(#+)\s+/gm, "\n$1 ")
          // Ensure proper line breaks for lists
          .replace(/^(\s*[-*])/gm, "\n$1")
          // Ensure proper line breaks for numbered lists
          .replace(/^(\s*\d+\.)/gm, "\n$1")
          // Remove any extra line breaks
          .replace(/\n{3,}/g, "\n\n")
          // Trim whitespace
          .trim();

        console.log("Summary length:", formattedSummary.length, "characters");

        // Return both the summary and metadata if available
        if (metadata) {
          return NextResponse.json({
            summary: formattedSummary,
            metadata: metadata,
          });
        }

        return NextResponse.json({ summary: formattedSummary });
      } catch (openaiError: any) {
        console.error("OpenAI API Error:", {
          message: openaiError.message,
          type: openaiError.type,
          stack: openaiError.stack,
          response: openaiError.response?.data,
        });
        return NextResponse.json(
          {
            error: `Failed to generate summary using AI: ${openaiError.message}`,
          },
          { status: 500 }
        );
      }
    } catch (transcriptError: any) {
      console.error(`[${videoId}] Transcript Fetching Error:`, {
        message: transcriptError.message,
        name: transcriptError.name,
        // Consider logging more properties if available, e.g., error code
        stack: transcriptError.stack,
      });

      // Provide more user-friendly error messages based on the error
      let userErrorMessage = `Failed to fetch video transcript: ${transcriptError.message}`;
      let statusCode = 404;

      if (
        transcriptError.message.includes("No captions data found") ||
        transcriptError.message.includes("Transcript is disabled") ||
        transcriptError.message.includes("No transcript tracks available") ||
        transcriptError.message.includes("No caption tracks found") ||
        transcriptError.message.includes("No cue groups found")
      ) {
        userErrorMessage =
          "This video doesn't have captions or transcripts available. Please try a different YouTube video that has captions enabled.";
      } else if (
        transcriptError.message.includes("Failed to fetch video page")
      ) {
        userErrorMessage =
          "Unable to access this YouTube video. The video might be private, restricted, or no longer available.";
      } else if (
        transcriptError.message.includes("Unauthorized") ||
        transcriptError.message.includes("API key")
      ) {
        statusCode = 500;
        userErrorMessage =
          "There was an authorization issue accessing YouTube's data. This is a server configuration problem.";
      }

      // Check if we should try to get some basic metadata anyway, even though transcript failed
      try {
        const basicMetadata = await fetchPodcastMetadata(videoId);

        return NextResponse.json(
          {
            error: userErrorMessage,
            metadata: basicMetadata, // Include metadata even when transcript fails
            videoId,
          },
          { status: statusCode }
        );
      } catch (metadataError) {
        // If even metadata fails, just return the error
        return NextResponse.json(
          { error: userErrorMessage, videoId },
          { status: statusCode }
        );
      }
    }
  } catch (error: any) {
    console.error("General Error:", {
      message: error.message,
      stack: error.stack,
    });
    return NextResponse.json(
      { error: `Failed to process request: ${error.message}` },
      { status: 500 }
    );
  }
}
</file>

</files>
